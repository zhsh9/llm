{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-attention\n",
    "\n",
    "$$ \n",
    "\\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mambaforge-pypy3\\envs\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional, Tuple\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModel, utils\n",
    "from bertviz import head_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initialize the SelfAttention module.\n",
    "        \n",
    "        Args:\n",
    "            embed_dim (int): The embedding dimension.\n",
    "        \"\"\"\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform self-attention operation.\n",
    "        \n",
    "        Args:\n",
    "            query (torch.Tensor): The query tensor.\n",
    "            key (torch.Tensor): The key tensor.\n",
    "            value (torch.Tensor): The value tensor.\n",
    "            mask (Optional[torch.Tensor]): The mask tensor.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: The output after attention operation.\n",
    "        \"\"\"\n",
    "        # [batch_size, seq_len, embed_dim]\n",
    "        Q = self.q_linear(x)\n",
    "        K = self.k_linear(x)\n",
    "        V = self.v_linear(x)\n",
    "\n",
    "        # [batch_size, seq_len, seq_len]\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
    "        \n",
    "        # Mask (opt.)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        # Softmax\n",
    "        attention = self.att_dropout(torch.softmax(scores, dim=-1))\n",
    "        \n",
    "        # att * value computation -> [batch_size, seq_len, embed_dim]\n",
    "        # att -> [batch_size, seq_len, seq_len]\n",
    "        return torch.matmul(attention, V), attention\n",
    "\n",
    "def test_self_attention():\n",
    "    # 设置参数\n",
    "    embed_dim = 64\n",
    "    seq_length = 10\n",
    "    batch_size = 2\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 创建 SelfAttention 实例\n",
    "    self_attention = SelfAttention(embed_dim).to(device)\n",
    "\n",
    "    # 生成随机输入\n",
    "    x = torch.randn(batch_size, seq_length, embed_dim).to(device)\n",
    "\n",
    "    # 前向传播\n",
    "    output, attention = self_attention(x)\n",
    "\n",
    "    # 打印输入和输出的形状\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Attention shape: {attention.shape}\")\n",
    "\n",
    "    # 断言检查输出形状是否正确\n",
    "    assert output.shape == x.shape, \"Output shape does not match input shape\"\n",
    "    assert attention.shape == (batch_size, seq_length, seq_length), \"Attention shape is incorrect\"\n",
    "\n",
    "    return self_attention\n",
    "\n",
    "def visualize_attention(attention_matrix):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention_matrix.detach().numpy(), annot=True, cmap='viridis')\n",
    "    plt.title(\"Self-Attention Visualization\")\n",
    "    plt.xlabel(\"Key\")\n",
    "    plt.ylabel(\"Query\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10, 64])\n",
      "Output shape: torch.Size([2, 10, 64])\n",
      "Attention shape: torch.Size([2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# 测试自注意力机制\n",
    "model = test_self_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mambaforge-pypy3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding dimension is: 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-db59d4dbffc64b51a70a0fb3c7c9ce85\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "/**\n * @fileoverview Transformer Visualization D3 javascript code.\n *\n *\n *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n *\n * Change log:\n *\n * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n * 12/29/20  Jesse Vig   Significant refactor.\n * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n * 07/25/21  Jesse Vig   Support layer filtering\n * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n **/\n\nrequire.config({\n  paths: {\n      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n  }\n});\n\nrequirejs(['jquery', 'd3'], function ($, d3) {\n\n    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.10879256576299667, 0.14285945892333984, 0.12787212431430817, 0.14199742674827576, 0.16082723438739777, 0.1622782200574875, 0.14530402421951294, 0.12118009477853775], [0.0, 0.13112863898277283, 0.14819948375225067, 0.13247908651828766, 0.142881840467453, 0.13646672666072845, 0.16397331655025482, 0.13970744609832764], [0.13645075261592865, 0.13606946170330048, 0.0, 0.1335671991109848, 0.0, 0.13542917370796204, 0.14984405040740967, 0.1337306946516037], [0.13829191029071808, 0.0, 0.13195715844631195, 0.13415391743183136, 0.13848890364170074, 0.14206407964229584, 0.17210033535957336, 0.12235099822282791], [0.13281692564487457, 0.13771651685237885, 0.1334766000509262, 0.13602052628993988, 0.1446351259946823, 0.14857423305511475, 0.14654085040092468, 0.0], [0.1254044473171234, 0.13481271266937256, 0.13746100664138794, 0.13742704689502716, 0.15229414403438568, 0.14448173344135284, 0.14845944941043854, 0.13077060878276825], [0.12804314494132996, 0.0, 0.13022854924201965, 0.1317891776561737, 0.15062271058559418, 0.16580404341220856, 0.14308476448059082, 0.1146484836935997], [0.13420957326889038, 0.12885984778404236, 0.14527049660682678, 0.14472156763076782, 0.14462411403656006, 0.14055302739143372, 0.1432778537273407, 0.12959468364715576]]]], \"left_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-db59d4dbffc64b51a70a0fb3c7c9ce85\", \"layer\": null, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.10879256576299667, 0.14285945892333984, 0.12787212431430817, 0.14199742674827576, 0.16082723438739777, 0.1622782200574875, 0.14530402421951294, 0.12118009477853775], [0.0, 0.13112863898277283, 0.14819948375225067, 0.13247908651828766, 0.142881840467453, 0.13646672666072845, 0.16397331655025482, 0.13970744609832764], [0.13645075261592865, 0.13606946170330048, 0.0, 0.1335671991109848, 0.0, 0.13542917370796204, 0.14984405040740967, 0.1337306946516037], [0.13829191029071808, 0.0, 0.13195715844631195, 0.13415391743183136, 0.13848890364170074, 0.14206407964229584, 0.17210033535957336, 0.12235099822282791], [0.13281692564487457, 0.13771651685237885, 0.1334766000509262, 0.13602052628993988, 0.1446351259946823, 0.14857423305511475, 0.14654085040092468, 0.0], [0.1254044473171234, 0.13481271266937256, 0.13746100664138794, 0.13742704689502716, 0.15229414403438568, 0.14448173344135284, 0.14845944941043854, 0.13077060878276825], [0.12804314494132996, 0.0, 0.13022854924201965, 0.1317891776561737, 0.15062271058559418, 0.16580404341220856, 0.14308476448059082, 0.1146484836935997], [0.13420957326889038, 0.12885984778404236, 0.14527049660682678, 0.14472156763076782, 0.14462411403656006, 0.14055302739143372, 0.1432778537273407, 0.12959468364715576]]]], \"left_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-db59d4dbffc64b51a70a0fb3c7c9ce85\", \"layer\": null, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n    const TEXT_SIZE = 15;\n    const BOXWIDTH = 110;\n    const BOXHEIGHT = 22.5;\n    const MATRIX_WIDTH = 115;\n    const CHECKBOX_SIZE = 20;\n    const TEXT_TOP = 30;\n\n    console.log(\"d3 version\", d3.version)\n    let headColors;\n    try {\n        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n    } catch (err) {\n        console.log('Older d3 version')\n        headColors = d3.scale.category10();\n    }\n    let config = {};\n    initialize();\n    renderVis();\n\n    function initialize() {\n        config.attention = params['attention'];\n        config.filter = params['default_filter'];\n        config.rootDivId = params['root_div_id'];\n        config.nLayers = config.attention[config.filter]['attn'].length;\n        config.nHeads = config.attention[config.filter]['attn'][0].length;\n        config.layers = params['include_layers']\n\n        if (params['heads']) {\n            config.headVis = new Array(config.nHeads).fill(false);\n            params['heads'].forEach(x => config.headVis[x] = true);\n        } else {\n            config.headVis = new Array(config.nHeads).fill(true);\n        }\n        config.initialTextLength = config.attention[config.filter].right_text.length;\n        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n        config.layer = config.layers[config.layer_seq]\n\n        let layerEl = $(`#${config.rootDivId} #layer`);\n        for (const layer of config.layers) {\n            layerEl.append($(\"<option />\").val(layer).text(layer));\n        }\n        layerEl.val(config.layer).change();\n        layerEl.on('change', function (e) {\n            config.layer = +e.currentTarget.value;\n            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n            renderVis();\n        });\n\n        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n            config.filter = e.currentTarget.value;\n            renderVis();\n        });\n    }\n\n    function renderVis() {\n\n        // Load parameters\n        const attnData = config.attention[config.filter];\n        const leftText = attnData.left_text;\n        const rightText = attnData.right_text;\n\n        // Select attention for given layer\n        const layerAttention = attnData.attn[config.layer_seq];\n\n        // Clear vis\n        $(`#${config.rootDivId} #vis`).empty();\n\n        // Determine size of visualization\n        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n        const svg = d3.select(`#${config.rootDivId} #vis`)\n            .append('svg')\n            .attr(\"width\", \"100%\")\n            .attr(\"height\", height + \"px\");\n\n        // Display tokens on left and right side of visualization\n        renderText(svg, leftText, true, layerAttention, 0);\n        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n\n        // Render attention arcs\n        renderAttention(svg, layerAttention);\n\n        // Draw squares at top of visualization, one for each head\n        drawCheckboxes(0, svg, layerAttention);\n    }\n\n    function renderText(svg, text, isLeft, attention, leftPos) {\n\n        const textContainer = svg.append(\"svg:g\")\n            .attr(\"id\", isLeft ? \"left\" : \"right\");\n\n        // Add attention highlights superimposed over words\n        textContainer.append(\"g\")\n            .classed(\"attentionBoxes\", true)\n            .selectAll(\"g\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\"rect\")\n            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function () {\n                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n                return leftPos + boxOffsets(headIndex);\n            })\n            .attr(\"y\", (+1) * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH / activeHeads())\n            .attr(\"height\", BOXHEIGHT)\n            .attr(\"fill\", function () {\n                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n            })\n            .style(\"opacity\", 0.0);\n\n        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n            .data(text)\n            .enter()\n            .append(\"g\");\n\n        // Add gray background that appears when hovering over text\n        tokenContainer.append(\"rect\")\n            .classed(\"background\", true)\n            .style(\"opacity\", 0.0)\n            .attr(\"fill\", \"lightgray\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH)\n            .attr(\"height\", BOXHEIGHT);\n\n        // Add token text\n        const textEl = tokenContainer.append(\"text\")\n            .text(d => d)\n            .attr(\"font-size\", TEXT_SIZE + \"px\")\n            .style(\"cursor\", \"default\")\n            .style(\"-webkit-user-select\", \"none\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n\n        if (isLeft) {\n            textEl.style(\"text-anchor\", \"end\")\n                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        } else {\n            textEl.style(\"text-anchor\", \"start\")\n                .attr(\"dx\", +0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        }\n\n        tokenContainer.on(\"mouseover\", function (d, index) {\n\n            // Show gray background for moused-over token\n            textContainer.selectAll(\".background\")\n                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n\n            // Reset visibility attribute for any previously highlighted attention arcs\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null)\n\n            // Hide group containing attention arcs\n            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n\n            // Set to visible appropriate attention arcs to be highlighted\n            if (isLeft) {\n                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            } else {\n                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            }\n\n            // Update color boxes superimposed over tokens\n            const id = isLeft ? \"right\" : \"left\";\n            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n            svg.select(\"#\" + id)\n                .selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .attr(\"head-index\", (d, i) => i)\n                .selectAll(\"rect\")\n                .attr(\"x\", function () {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    return leftPos + boxOffsets(headIndex);\n                })\n                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n                .attr(\"width\", BOXWIDTH / activeHeads())\n                .attr(\"height\", BOXHEIGHT)\n                .style(\"opacity\", function (d) {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    if (config.headVis[headIndex])\n                        if (d) {\n                            return d[index];\n                        } else {\n                            return 0.0;\n                        }\n                    else\n                        return 0.0;\n                });\n        });\n\n        textContainer.on(\"mouseleave\", function () {\n\n            // Unhighlight selected token\n            d3.select(this).selectAll(\".background\")\n                .style(\"opacity\", 0.0);\n\n            // Reset visibility attributes for previously selected lines\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null) ;\n            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n\n            // Reset highlights superimposed over tokens\n            svg.selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .selectAll(\"rect\")\n                .style(\"opacity\", 0.0);\n        });\n    }\n\n    function renderAttention(svg, attention) {\n\n        // Remove previous dom elements\n        svg.select(\"#attention\").remove();\n\n        // Add new elements\n        svg.append(\"g\")\n            .attr(\"id\", \"attention\") // Container for all attention arcs\n            .selectAll(\".headAttention\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .classed(\"headAttention\", true) // Group attention arcs by head\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\".tokenAttention\")\n            .data(d => d)\n            .enter()\n            .append(\"g\")\n            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n            .attr(\"left-token-index\", (d, i) => i)\n            .selectAll(\"line\")\n            .data(d => d)\n            .enter()\n            .append(\"line\")\n            .attr(\"x1\", BOXWIDTH)\n            .attr(\"y1\", function () {\n                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n            })\n            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n            .attr(\"stroke-width\", 2)\n            .attr(\"stroke\", function () {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                return headColors(headIndex)\n            })\n            .attr(\"left-token-index\", function () {\n                return +this.parentNode.getAttribute(\"left-token-index\")\n            })\n            .attr(\"right-token-index\", (d, i) => i)\n        ;\n        updateAttention(svg)\n    }\n\n    function updateAttention(svg) {\n        svg.select(\"#attention\")\n            .selectAll(\"line\")\n            .attr(\"stroke-opacity\", function (d) {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                // If head is selected\n                if (config.headVis[headIndex]) {\n                    // Set opacity to attention weight divided by number of active heads\n                    return d / activeHeads()\n                } else {\n                    return 0.0;\n                }\n            })\n    }\n\n    function boxOffsets(i) {\n        const numHeadsAbove = config.headVis.reduce(\n            function (acc, val, cur) {\n                return val && cur < i ? acc + 1 : acc;\n            }, 0);\n        return numHeadsAbove * (BOXWIDTH / activeHeads());\n    }\n\n    function activeHeads() {\n        return config.headVis.reduce(function (acc, val) {\n            return val ? acc + 1 : acc;\n        }, 0);\n    }\n\n    function drawCheckboxes(top, svg) {\n        const checkboxContainer = svg.append(\"g\");\n        const checkbox = checkboxContainer.selectAll(\"rect\")\n            .data(config.headVis)\n            .enter()\n            .append(\"rect\")\n            .attr(\"fill\", (d, i) => headColors(i))\n            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n            .attr(\"y\", top)\n            .attr(\"width\", CHECKBOX_SIZE)\n            .attr(\"height\", CHECKBOX_SIZE);\n\n        function updateCheckboxes() {\n            checkboxContainer.selectAll(\"rect\")\n                .data(config.headVis)\n                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n        }\n\n        updateCheckboxes();\n\n        checkbox.on(\"click\", function (d, i) {\n            if (config.headVis[i] && activeHeads() === 1) return;\n            config.headVis[i] = !config.headVis[i];\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n\n        checkbox.on(\"dblclick\", function (d, i) {\n            // If we double click on the only active head then reset\n            if (config.headVis[i] && activeHeads() === 1) {\n                config.headVis = new Array(config.nHeads).fill(true);\n            } else {\n                config.headVis = new Array(config.nHeads).fill(false);\n                config.headVis[i] = true;\n            }\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n    }\n\n    function lighten(color) {\n        const c = d3.hsl(color);\n        const increment = (1 - c.l) * 0.6;\n        c.l += increment;\n        c.s -= increment;\n        return c;\n    }\n\n    function transpose(mat) {\n        return mat[0].map(function (col, i) {\n            return mat.map(function (row) {\n                return row[i];\n            });\n        });\n    }\n\n});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 加载预训练 tokenizer 和模型，可视化注意力机制\n",
    "# huggingface-cli download --resume-download google-bert/bert-base-uncased --local-dir .\\bert-base-uncased\\\n",
    "model_name = \"bert-base-uncased\"\n",
    "input_text = \"The cat sat on the mat\"\n",
    "\n",
    "# 加载tokenizer和完整的预训练模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# 获取embed_dim\n",
    "embed_dim = pretrained_model.config.hidden_size\n",
    "print(f\"The embedding dimension is: {embed_dim}\")\n",
    "\n",
    "# 初始化你的SelfAttention模型\n",
    "model = SelfAttention(embed_dim=embed_dim)\n",
    "\n",
    "tokenized = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "with torch.no_grad():\n",
    "    inputs = pretrained_model(tokenized).last_hidden_state\n",
    "\n",
    "output, attention = model(inputs)  # Run model & Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized[0])  # Convert input ids to token strings\n",
    "\n",
    "attention = attention.unsqueeze(1).view(1, 1, 1, len(tokenized[0]), len(tokenized[0]))  # Self-attention only has one head\n",
    "head_view(attention, tokens)  # Display model view, attention dim: (batch_size, num_layers, num_heads, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-head Attention\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where } \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Where the projections are parameter matrices } W_i^Q \\in \\mathbb{R}^{d_\\text{model} \\times d_k}, W_i^K \\in \\mathbb{R}^{d_\\text{model} \\times d_k}, W_i^V \\in \\mathbb{R}^{d_\\text{model} \\times d_v} \\text{and } W^O \\in \\mathbb{R}^{hd_v \\times d_\\text{model}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initialize the MultiHeadAttention module.\n",
    "        \n",
    "        Args:\n",
    "            embed_dim (int): The embedding dimension.\n",
    "            num_heads (int): The number of attention heads.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        \n",
    "        self.q_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform multi-head attention operation.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of shape [batch_size, seq_len, embed_dim].\n",
    "            mask (Optional[torch.Tensor]): The mask tensor of shape [batch_size, seq_len, seq_len].\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: The output after multi-head attention operation.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = self.q_linear(x)\n",
    "        K = self.k_linear(x)\n",
    "        V = self.v_linear(x)\n",
    "        \n",
    "        # Split into multiple heads\n",
    "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        att_weights = Q @ K.transpose(-2, -1) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        # Mask (opt.)\n",
    "        if mask is not None:\n",
    "            att_weights = att_weights.masked_fill(mask.unsqueeze(1) == 0, float('-inf'))\n",
    "        \n",
    "        # Softmax\n",
    "        attention = self.att_dropout(torch.softmax(att_weights, dim=-1))\n",
    "        \n",
    "        # Attention output\n",
    "        out = attention @ V\n",
    "        \n",
    "        # Concatenate heads\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)\n",
    "        \n",
    "        # Final linear projection\n",
    "        return self.out_proj(out), attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mambaforge-pypy3\\envs\\llm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding dimension is: 768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-9555d04b1a044db596db7095a79158f9\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "/**\n * @fileoverview Transformer Visualization D3 javascript code.\n *\n *\n *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n *\n * Change log:\n *\n * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n * 12/29/20  Jesse Vig   Significant refactor.\n * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n * 07/25/21  Jesse Vig   Support layer filtering\n * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n **/\n\nrequire.config({\n  paths: {\n      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n  }\n});\n\nrequirejs(['jquery', 'd3'], function ($, d3) {\n\n    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.12226781994104385, 0.13803167641162872, 0.1403956413269043, 0.13501626253128052, 0.14332884550094604, 0.1364544928073883, 0.1413380652666092, 0.15427827835083008], [0.1509772539138794, 0.14057591557502747, 0.14699287712574005, 0.1381049007177353, 0.0, 0.0, 0.1470744013786316, 0.11537305265665054], [0.1538097858428955, 0.1562134027481079, 0.13949833810329437, 0.135507732629776, 0.0, 0.1341480016708374, 0.14215821027755737, 0.1212572231888771], [0.1512899249792099, 0.14092233777046204, 0.0, 0.1336659938097, 0.1390693336725235, 0.13221482932567596, 0.1377897560596466, 0.12592589855194092], [0.15356430411338806, 0.0, 0.14429761469364166, 0.0, 0.13790053129196167, 0.1332513839006424, 0.1465795338153839, 0.11288540065288544], [0.14518018066883087, 0.14201289415359497, 0.14592933654785156, 0.14044901728630066, 0.13469435274600983, 0.1317141056060791, 0.14408069849014282, 0.12705062329769135], [0.15191048383712769, 0.0, 0.12835097312927246, 0.1355115920305252, 0.13266897201538086, 0.14088258147239685, 0.15887030959129333, 0.11440932005643845], [0.14110137522220612, 0.14364491403102875, 0.13020232319831848, 0.13532261550426483, 0.13333144783973694, 0.14512960612773895, 0.15883247554302216, 0.12354648858308792]], [[0.1383727341890335, 0.14085857570171356, 0.14274723827838898, 0.13517722487449646, 0.13709011673927307, 0.13130055367946625, 0.13383345305919647, 0.15173135697841644], [0.13912546634674072, 0.12992410361766815, 0.14432622492313385, 0.0, 0.14167189598083496, 0.13682317733764648, 0.13258841633796692, 0.14256729185581207], [0.1404719352722168, 0.13071775436401367, 0.1503210812807083, 0.1346423178911209, 0.1365477591753006, 0.13793106377124786, 0.13238582015037537, 0.14809346199035645], [0.12974369525909424, 0.13673937320709229, 0.13189148902893066, 0.14100953936576843, 0.14492560923099518, 0.1416575312614441, 0.13237226009368896, 0.15277156233787537], [0.0, 0.1289067268371582, 0.14322353899478912, 0.15445290505886078, 0.14407142996788025, 0.12979379296302795, 0.13812275230884552, 0.15668432414531708], [0.12170512974262238, 0.13002999126911163, 0.0, 0.14448262751102448, 0.0, 0.13296900689601898, 0.0, 0.160867378115654], [0.1360810399055481, 0.13301123678684235, 0.15775026381015778, 0.0, 0.12673988938331604, 0.0, 0.1280544251203537, 0.16976839303970337], [0.15775170922279358, 0.139811709523201, 0.11288686841726303, 0.14198356866836548, 0.0, 0.13721629977226257, 0.16039983928203583, 0.0]], [[0.1594223976135254, 0.0, 0.1325114369392395, 0.12538450956344604, 0.12152466922998428, 0.12983250617980957, 0.15832410752773285, 0.15008239448070526], [0.0, 0.135154590010643, 0.14163713157176971, 0.1350940614938736, 0.11789464950561523, 0.1393580287694931, 0.14796817302703857, 0.1390034556388855], [0.0, 0.12971365451812744, 0.14499995112419128, 0.13334690034389496, 0.12481378018856049, 0.1365569829940796, 0.13598908483982086, 0.150488942861557], [0.14793184399604797, 0.13948440551757812, 0.14213994145393372, 0.13683918118476868, 0.0, 0.14587658643722534, 0.14017942547798157, 0.13809360563755035], [0.14582136273384094, 0.0, 0.14939716458320618, 0.13598573207855225, 0.11811766773462296, 0.0, 0.1361636519432068, 0.15523116290569305], [0.15014418959617615, 0.1315111666917801, 0.14845579862594604, 0.1356220543384552, 0.12193749099969864, 0.14234118163585663, 0.1418071836233139, 0.1392921656370163], [0.16018955409526825, 0.12057919055223465, 0.14108173549175262, 0.13256654143333435, 0.11726123839616776, 0.13125213980674744, 0.15445873141288757, 0.15372204780578613], [0.14640936255455017, 0.1328330934047699, 0.13823945820331573, 0.13409662246704102, 0.1274101734161377, 0.13696293532848358, 0.14997735619544983, 0.14518219232559204]], [[0.13970546424388885, 0.13935010135173798, 0.12446608394384384, 0.14164979755878448, 0.13642077147960663, 0.15046024322509766, 0.15519897639751434, 0.12385977059602737], [0.14369739592075348, 0.14039602875709534, 0.13226275146007538, 0.1407145857810974, 0.13966073095798492, 0.13648542761802673, 0.1472807228565216, 0.13061347603797913], [0.1479102373123169, 0.1321401745080948, 0.12631702423095703, 0.13792112469673157, 0.12847985327243805, 0.13053131103515625, 0.14520078897476196, 0.0], [0.1360177844762802, 0.1322358399629593, 0.13890650868415833, 0.14501050114631653, 0.1445641964673996, 0.14021232724189758, 0.13310323655605316, 0.1410607546567917], [0.1287921518087387, 0.13022546470165253, 0.14433924853801727, 0.1460200995206833, 0.14317385852336884, 0.14148467779159546, 0.15017381310462952, 0.0], [0.1347365826368332, 0.14054420590400696, 0.14170783758163452, 0.14246366918087006, 0.1423538327217102, 0.13945241272449493, 0.1464269906282425, 0.12342560291290283], [0.13483114540576935, 0.13451199233531952, 0.11889780312776566, 0.14511319994926453, 0.14358435571193695, 0.12677040696144104, 0.1500856727361679, 0.157316654920578], [0.15097041428089142, 0.14049167931079865, 0.0, 0.1317170262336731, 0.14426220953464508, 0.13881702721118927, 0.15738828480243683, 0.13238045573234558]], [[0.14043568074703217, 0.14438217878341675, 0.13619017601013184, 0.0, 0.1394769847393036, 0.13795159757137299, 0.13406877219676971, 0.14653249084949493], [0.0, 0.14578591287136078, 0.1376124918460846, 0.13421647250652313, 0.13104793429374695, 0.14018188416957855, 0.13167399168014526, 0.1334320455789566], [0.13068075478076935, 0.13645224273204803, 0.14159269630908966, 0.14114363491535187, 0.14464619755744934, 0.13569264113903046, 0.14652571082115173, 0.13437724113464355], [0.0, 0.13440440595149994, 0.13309761881828308, 0.1334189474582672, 0.14063140749931335, 0.13474538922309875, 0.0, 0.1410093456506729], [0.13943029940128326, 0.13771791756153107, 0.128581702709198, 0.13342633843421936, 0.13910606503486633, 0.14109788835048676, 0.1470685601234436, 0.14468246698379517], [0.15148192644119263, 0.14842334389686584, 0.0, 0.13783442974090576, 0.13998833298683167, 0.14099270105361938, 0.1333555430173874, 0.12503258883953094], [0.0, 0.13460282981395721, 0.1380072683095932, 0.12788167595863342, 0.12778407335281372, 0.1367795616388321, 0.1372675597667694, 0.13873586058616638], [0.12522771954536438, 0.13001540303230286, 0.0, 0.15210755169391632, 0.14835688471794128, 0.1368771493434906, 0.13173384964466095, 0.15741834044456482]], [[0.13945384323596954, 0.13884900510311127, 0.0, 0.14812855422496796, 0.13041938841342926, 0.1393498331308365, 0.14730866253376007, 0.14006789028644562], [0.13271692395210266, 0.14786574244499207, 0.15354427695274353, 0.13195815682411194, 0.13039468228816986, 0.13709646463394165, 0.13394412398338318, 0.14359083771705627], [0.13292278349399567, 0.14251816272735596, 0.15910182893276215, 0.13718268275260925, 0.0, 0.1337241679430008, 0.12852679193019867, 0.14068658649921417], [0.1301683485507965, 0.15361279249191284, 0.1597549319267273, 0.14015012979507446, 0.1421540379524231, 0.1427309662103653, 0.12075803428888321, 0.12178197503089905], [0.14336887001991272, 0.14167636632919312, 0.14915010333061218, 0.14175349473953247, 0.14302986860275269, 0.13542605936527252, 0.12574143707752228, 0.13096491992473602], [0.1360785961151123, 0.15227340161800385, 0.14738544821739197, 0.13162440061569214, 0.13307741284370422, 0.13865913450717926, 0.1352071315050125, 0.1368056833744049], [0.15897919237613678, 0.14650185406208038, 0.16088975965976715, 0.12420325726270676, 0.124062180519104, 0.12891298532485962, 0.1467399150133133, 0.12082201987504959], [0.1382511705160141, 0.14434291422367096, 0.13694658875465393, 0.14074771106243134, 0.13838604092597961, 0.15645167231559753, 0.14185795187950134, 0.11412713676691055]], [[0.14401762187480927, 0.12708234786987305, 0.14618746936321259, 0.13778702914714813, 0.14897309243679047, 0.1328745037317276, 0.1384391039609909, 0.13575002551078796], [0.1461830586194992, 0.13432693481445312, 0.1523669809103012, 0.1376134306192398, 0.14082904160022736, 0.13436895608901978, 0.12688054144382477, 0.1385422646999359], [0.1234186440706253, 0.0, 0.15125347673892975, 0.1491106003522873, 0.15146812796592712, 0.0, 0.1367289125919342, 0.13557171821594238], [0.1142919585108757, 0.1369631141424179, 0.0, 0.15062293410301208, 0.14138321578502655, 0.14503660798072815, 0.1364036351442337, 0.0], [0.12446650862693787, 0.1353456676006317, 0.15386618673801422, 0.14134754240512848, 0.1448223888874054, 0.1415511518716812, 0.1403471678495407, 0.129364475607872], [0.13509337604045868, 0.13473546504974365, 0.1555163711309433, 0.0, 0.14407120645046234, 0.14015492796897888, 0.0, 0.12463688850402832], [0.13615480065345764, 0.13206611573696136, 0.14188675582408905, 0.13780716061592102, 0.1525447517633438, 0.13928145170211792, 0.14614169299602509, 0.12522844970226288], [0.13338252902030945, 0.13863298296928406, 0.13584989309310913, 0.13878820836544037, 0.0, 0.13649801909923553, 0.0, 0.13869445025920868]], [[0.15738533437252045, 0.15329626202583313, 0.12828078866004944, 0.12876994907855988, 0.14659880101680756, 0.1420227289199829, 0.13003799319267273, 0.12471921741962433], [0.14055582880973816, 0.14323997497558594, 0.12382154166698456, 0.14407706260681152, 0.13373415172100067, 0.14545011520385742, 0.134099543094635, 0.14613299071788788], [0.11756874620914459, 0.14469321072101593, 0.12997043132781982, 0.14576230943202972, 0.1398293375968933, 0.143644779920578, 0.1479160040616989, 0.14172635972499847], [0.12431296706199646, 0.13501136004924774, 0.12380639463663101, 0.13784104585647583, 0.14553183317184448, 0.14960695803165436, 0.13692039251327515, 0.15808025002479553], [0.11045171320438385, 0.13829831779003143, 0.13386371731758118, 0.1411069929599762, 0.15131878852844238, 0.15136821568012238, 0.14173738658428192, 0.14296601712703705], [0.13965551555156708, 0.1388154774904251, 0.12970706820487976, 0.12986457347869873, 0.13117972016334534, 0.14361125230789185, 0.0, 0.1550508439540863], [0.0, 0.0, 0.0, 0.1291314661502838, 0.13931392133235931, 0.128328338265419, 0.1330786794424057, 0.1786503940820694], [0.15120840072631836, 0.11733292788267136, 0.12324850261211395, 0.12623657286167145, 0.0, 0.12823975086212158, 0.15025955438613892, 0.1822652667760849]]]], \"left_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-9555d04b1a044db596db7095a79158f9\", \"layer\": null, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.12226781994104385, 0.13803167641162872, 0.1403956413269043, 0.13501626253128052, 0.14332884550094604, 0.1364544928073883, 0.1413380652666092, 0.15427827835083008], [0.1509772539138794, 0.14057591557502747, 0.14699287712574005, 0.1381049007177353, 0.0, 0.0, 0.1470744013786316, 0.11537305265665054], [0.1538097858428955, 0.1562134027481079, 0.13949833810329437, 0.135507732629776, 0.0, 0.1341480016708374, 0.14215821027755737, 0.1212572231888771], [0.1512899249792099, 0.14092233777046204, 0.0, 0.1336659938097, 0.1390693336725235, 0.13221482932567596, 0.1377897560596466, 0.12592589855194092], [0.15356430411338806, 0.0, 0.14429761469364166, 0.0, 0.13790053129196167, 0.1332513839006424, 0.1465795338153839, 0.11288540065288544], [0.14518018066883087, 0.14201289415359497, 0.14592933654785156, 0.14044901728630066, 0.13469435274600983, 0.1317141056060791, 0.14408069849014282, 0.12705062329769135], [0.15191048383712769, 0.0, 0.12835097312927246, 0.1355115920305252, 0.13266897201538086, 0.14088258147239685, 0.15887030959129333, 0.11440932005643845], [0.14110137522220612, 0.14364491403102875, 0.13020232319831848, 0.13532261550426483, 0.13333144783973694, 0.14512960612773895, 0.15883247554302216, 0.12354648858308792]], [[0.1383727341890335, 0.14085857570171356, 0.14274723827838898, 0.13517722487449646, 0.13709011673927307, 0.13130055367946625, 0.13383345305919647, 0.15173135697841644], [0.13912546634674072, 0.12992410361766815, 0.14432622492313385, 0.0, 0.14167189598083496, 0.13682317733764648, 0.13258841633796692, 0.14256729185581207], [0.1404719352722168, 0.13071775436401367, 0.1503210812807083, 0.1346423178911209, 0.1365477591753006, 0.13793106377124786, 0.13238582015037537, 0.14809346199035645], [0.12974369525909424, 0.13673937320709229, 0.13189148902893066, 0.14100953936576843, 0.14492560923099518, 0.1416575312614441, 0.13237226009368896, 0.15277156233787537], [0.0, 0.1289067268371582, 0.14322353899478912, 0.15445290505886078, 0.14407142996788025, 0.12979379296302795, 0.13812275230884552, 0.15668432414531708], [0.12170512974262238, 0.13002999126911163, 0.0, 0.14448262751102448, 0.0, 0.13296900689601898, 0.0, 0.160867378115654], [0.1360810399055481, 0.13301123678684235, 0.15775026381015778, 0.0, 0.12673988938331604, 0.0, 0.1280544251203537, 0.16976839303970337], [0.15775170922279358, 0.139811709523201, 0.11288686841726303, 0.14198356866836548, 0.0, 0.13721629977226257, 0.16039983928203583, 0.0]], [[0.1594223976135254, 0.0, 0.1325114369392395, 0.12538450956344604, 0.12152466922998428, 0.12983250617980957, 0.15832410752773285, 0.15008239448070526], [0.0, 0.135154590010643, 0.14163713157176971, 0.1350940614938736, 0.11789464950561523, 0.1393580287694931, 0.14796817302703857, 0.1390034556388855], [0.0, 0.12971365451812744, 0.14499995112419128, 0.13334690034389496, 0.12481378018856049, 0.1365569829940796, 0.13598908483982086, 0.150488942861557], [0.14793184399604797, 0.13948440551757812, 0.14213994145393372, 0.13683918118476868, 0.0, 0.14587658643722534, 0.14017942547798157, 0.13809360563755035], [0.14582136273384094, 0.0, 0.14939716458320618, 0.13598573207855225, 0.11811766773462296, 0.0, 0.1361636519432068, 0.15523116290569305], [0.15014418959617615, 0.1315111666917801, 0.14845579862594604, 0.1356220543384552, 0.12193749099969864, 0.14234118163585663, 0.1418071836233139, 0.1392921656370163], [0.16018955409526825, 0.12057919055223465, 0.14108173549175262, 0.13256654143333435, 0.11726123839616776, 0.13125213980674744, 0.15445873141288757, 0.15372204780578613], [0.14640936255455017, 0.1328330934047699, 0.13823945820331573, 0.13409662246704102, 0.1274101734161377, 0.13696293532848358, 0.14997735619544983, 0.14518219232559204]], [[0.13970546424388885, 0.13935010135173798, 0.12446608394384384, 0.14164979755878448, 0.13642077147960663, 0.15046024322509766, 0.15519897639751434, 0.12385977059602737], [0.14369739592075348, 0.14039602875709534, 0.13226275146007538, 0.1407145857810974, 0.13966073095798492, 0.13648542761802673, 0.1472807228565216, 0.13061347603797913], [0.1479102373123169, 0.1321401745080948, 0.12631702423095703, 0.13792112469673157, 0.12847985327243805, 0.13053131103515625, 0.14520078897476196, 0.0], [0.1360177844762802, 0.1322358399629593, 0.13890650868415833, 0.14501050114631653, 0.1445641964673996, 0.14021232724189758, 0.13310323655605316, 0.1410607546567917], [0.1287921518087387, 0.13022546470165253, 0.14433924853801727, 0.1460200995206833, 0.14317385852336884, 0.14148467779159546, 0.15017381310462952, 0.0], [0.1347365826368332, 0.14054420590400696, 0.14170783758163452, 0.14246366918087006, 0.1423538327217102, 0.13945241272449493, 0.1464269906282425, 0.12342560291290283], [0.13483114540576935, 0.13451199233531952, 0.11889780312776566, 0.14511319994926453, 0.14358435571193695, 0.12677040696144104, 0.1500856727361679, 0.157316654920578], [0.15097041428089142, 0.14049167931079865, 0.0, 0.1317170262336731, 0.14426220953464508, 0.13881702721118927, 0.15738828480243683, 0.13238045573234558]], [[0.14043568074703217, 0.14438217878341675, 0.13619017601013184, 0.0, 0.1394769847393036, 0.13795159757137299, 0.13406877219676971, 0.14653249084949493], [0.0, 0.14578591287136078, 0.1376124918460846, 0.13421647250652313, 0.13104793429374695, 0.14018188416957855, 0.13167399168014526, 0.1334320455789566], [0.13068075478076935, 0.13645224273204803, 0.14159269630908966, 0.14114363491535187, 0.14464619755744934, 0.13569264113903046, 0.14652571082115173, 0.13437724113464355], [0.0, 0.13440440595149994, 0.13309761881828308, 0.1334189474582672, 0.14063140749931335, 0.13474538922309875, 0.0, 0.1410093456506729], [0.13943029940128326, 0.13771791756153107, 0.128581702709198, 0.13342633843421936, 0.13910606503486633, 0.14109788835048676, 0.1470685601234436, 0.14468246698379517], [0.15148192644119263, 0.14842334389686584, 0.0, 0.13783442974090576, 0.13998833298683167, 0.14099270105361938, 0.1333555430173874, 0.12503258883953094], [0.0, 0.13460282981395721, 0.1380072683095932, 0.12788167595863342, 0.12778407335281372, 0.1367795616388321, 0.1372675597667694, 0.13873586058616638], [0.12522771954536438, 0.13001540303230286, 0.0, 0.15210755169391632, 0.14835688471794128, 0.1368771493434906, 0.13173384964466095, 0.15741834044456482]], [[0.13945384323596954, 0.13884900510311127, 0.0, 0.14812855422496796, 0.13041938841342926, 0.1393498331308365, 0.14730866253376007, 0.14006789028644562], [0.13271692395210266, 0.14786574244499207, 0.15354427695274353, 0.13195815682411194, 0.13039468228816986, 0.13709646463394165, 0.13394412398338318, 0.14359083771705627], [0.13292278349399567, 0.14251816272735596, 0.15910182893276215, 0.13718268275260925, 0.0, 0.1337241679430008, 0.12852679193019867, 0.14068658649921417], [0.1301683485507965, 0.15361279249191284, 0.1597549319267273, 0.14015012979507446, 0.1421540379524231, 0.1427309662103653, 0.12075803428888321, 0.12178197503089905], [0.14336887001991272, 0.14167636632919312, 0.14915010333061218, 0.14175349473953247, 0.14302986860275269, 0.13542605936527252, 0.12574143707752228, 0.13096491992473602], [0.1360785961151123, 0.15227340161800385, 0.14738544821739197, 0.13162440061569214, 0.13307741284370422, 0.13865913450717926, 0.1352071315050125, 0.1368056833744049], [0.15897919237613678, 0.14650185406208038, 0.16088975965976715, 0.12420325726270676, 0.124062180519104, 0.12891298532485962, 0.1467399150133133, 0.12082201987504959], [0.1382511705160141, 0.14434291422367096, 0.13694658875465393, 0.14074771106243134, 0.13838604092597961, 0.15645167231559753, 0.14185795187950134, 0.11412713676691055]], [[0.14401762187480927, 0.12708234786987305, 0.14618746936321259, 0.13778702914714813, 0.14897309243679047, 0.1328745037317276, 0.1384391039609909, 0.13575002551078796], [0.1461830586194992, 0.13432693481445312, 0.1523669809103012, 0.1376134306192398, 0.14082904160022736, 0.13436895608901978, 0.12688054144382477, 0.1385422646999359], [0.1234186440706253, 0.0, 0.15125347673892975, 0.1491106003522873, 0.15146812796592712, 0.0, 0.1367289125919342, 0.13557171821594238], [0.1142919585108757, 0.1369631141424179, 0.0, 0.15062293410301208, 0.14138321578502655, 0.14503660798072815, 0.1364036351442337, 0.0], [0.12446650862693787, 0.1353456676006317, 0.15386618673801422, 0.14134754240512848, 0.1448223888874054, 0.1415511518716812, 0.1403471678495407, 0.129364475607872], [0.13509337604045868, 0.13473546504974365, 0.1555163711309433, 0.0, 0.14407120645046234, 0.14015492796897888, 0.0, 0.12463688850402832], [0.13615480065345764, 0.13206611573696136, 0.14188675582408905, 0.13780716061592102, 0.1525447517633438, 0.13928145170211792, 0.14614169299602509, 0.12522844970226288], [0.13338252902030945, 0.13863298296928406, 0.13584989309310913, 0.13878820836544037, 0.0, 0.13649801909923553, 0.0, 0.13869445025920868]], [[0.15738533437252045, 0.15329626202583313, 0.12828078866004944, 0.12876994907855988, 0.14659880101680756, 0.1420227289199829, 0.13003799319267273, 0.12471921741962433], [0.14055582880973816, 0.14323997497558594, 0.12382154166698456, 0.14407706260681152, 0.13373415172100067, 0.14545011520385742, 0.134099543094635, 0.14613299071788788], [0.11756874620914459, 0.14469321072101593, 0.12997043132781982, 0.14576230943202972, 0.1398293375968933, 0.143644779920578, 0.1479160040616989, 0.14172635972499847], [0.12431296706199646, 0.13501136004924774, 0.12380639463663101, 0.13784104585647583, 0.14553183317184448, 0.14960695803165436, 0.13692039251327515, 0.15808025002479553], [0.11045171320438385, 0.13829831779003143, 0.13386371731758118, 0.1411069929599762, 0.15131878852844238, 0.15136821568012238, 0.14173738658428192, 0.14296601712703705], [0.13965551555156708, 0.1388154774904251, 0.12970706820487976, 0.12986457347869873, 0.13117972016334534, 0.14361125230789185, 0.0, 0.1550508439540863], [0.0, 0.0, 0.0, 0.1291314661502838, 0.13931392133235931, 0.128328338265419, 0.1330786794424057, 0.1786503940820694], [0.15120840072631836, 0.11733292788267136, 0.12324850261211395, 0.12623657286167145, 0.0, 0.12823975086212158, 0.15025955438613892, 0.1822652667760849]]]], \"left_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"], \"right_text\": [\"[CLS]\", \"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\", \"[SEP]\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-9555d04b1a044db596db7095a79158f9\", \"layer\": null, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n    const TEXT_SIZE = 15;\n    const BOXWIDTH = 110;\n    const BOXHEIGHT = 22.5;\n    const MATRIX_WIDTH = 115;\n    const CHECKBOX_SIZE = 20;\n    const TEXT_TOP = 30;\n\n    console.log(\"d3 version\", d3.version)\n    let headColors;\n    try {\n        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n    } catch (err) {\n        console.log('Older d3 version')\n        headColors = d3.scale.category10();\n    }\n    let config = {};\n    initialize();\n    renderVis();\n\n    function initialize() {\n        config.attention = params['attention'];\n        config.filter = params['default_filter'];\n        config.rootDivId = params['root_div_id'];\n        config.nLayers = config.attention[config.filter]['attn'].length;\n        config.nHeads = config.attention[config.filter]['attn'][0].length;\n        config.layers = params['include_layers']\n\n        if (params['heads']) {\n            config.headVis = new Array(config.nHeads).fill(false);\n            params['heads'].forEach(x => config.headVis[x] = true);\n        } else {\n            config.headVis = new Array(config.nHeads).fill(true);\n        }\n        config.initialTextLength = config.attention[config.filter].right_text.length;\n        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n        config.layer = config.layers[config.layer_seq]\n\n        let layerEl = $(`#${config.rootDivId} #layer`);\n        for (const layer of config.layers) {\n            layerEl.append($(\"<option />\").val(layer).text(layer));\n        }\n        layerEl.val(config.layer).change();\n        layerEl.on('change', function (e) {\n            config.layer = +e.currentTarget.value;\n            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n            renderVis();\n        });\n\n        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n            config.filter = e.currentTarget.value;\n            renderVis();\n        });\n    }\n\n    function renderVis() {\n\n        // Load parameters\n        const attnData = config.attention[config.filter];\n        const leftText = attnData.left_text;\n        const rightText = attnData.right_text;\n\n        // Select attention for given layer\n        const layerAttention = attnData.attn[config.layer_seq];\n\n        // Clear vis\n        $(`#${config.rootDivId} #vis`).empty();\n\n        // Determine size of visualization\n        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n        const svg = d3.select(`#${config.rootDivId} #vis`)\n            .append('svg')\n            .attr(\"width\", \"100%\")\n            .attr(\"height\", height + \"px\");\n\n        // Display tokens on left and right side of visualization\n        renderText(svg, leftText, true, layerAttention, 0);\n        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n\n        // Render attention arcs\n        renderAttention(svg, layerAttention);\n\n        // Draw squares at top of visualization, one for each head\n        drawCheckboxes(0, svg, layerAttention);\n    }\n\n    function renderText(svg, text, isLeft, attention, leftPos) {\n\n        const textContainer = svg.append(\"svg:g\")\n            .attr(\"id\", isLeft ? \"left\" : \"right\");\n\n        // Add attention highlights superimposed over words\n        textContainer.append(\"g\")\n            .classed(\"attentionBoxes\", true)\n            .selectAll(\"g\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\"rect\")\n            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function () {\n                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n                return leftPos + boxOffsets(headIndex);\n            })\n            .attr(\"y\", (+1) * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH / activeHeads())\n            .attr(\"height\", BOXHEIGHT)\n            .attr(\"fill\", function () {\n                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n            })\n            .style(\"opacity\", 0.0);\n\n        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n            .data(text)\n            .enter()\n            .append(\"g\");\n\n        // Add gray background that appears when hovering over text\n        tokenContainer.append(\"rect\")\n            .classed(\"background\", true)\n            .style(\"opacity\", 0.0)\n            .attr(\"fill\", \"lightgray\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH)\n            .attr(\"height\", BOXHEIGHT);\n\n        // Add token text\n        const textEl = tokenContainer.append(\"text\")\n            .text(d => d)\n            .attr(\"font-size\", TEXT_SIZE + \"px\")\n            .style(\"cursor\", \"default\")\n            .style(\"-webkit-user-select\", \"none\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n\n        if (isLeft) {\n            textEl.style(\"text-anchor\", \"end\")\n                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        } else {\n            textEl.style(\"text-anchor\", \"start\")\n                .attr(\"dx\", +0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        }\n\n        tokenContainer.on(\"mouseover\", function (d, index) {\n\n            // Show gray background for moused-over token\n            textContainer.selectAll(\".background\")\n                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n\n            // Reset visibility attribute for any previously highlighted attention arcs\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null)\n\n            // Hide group containing attention arcs\n            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n\n            // Set to visible appropriate attention arcs to be highlighted\n            if (isLeft) {\n                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            } else {\n                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            }\n\n            // Update color boxes superimposed over tokens\n            const id = isLeft ? \"right\" : \"left\";\n            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n            svg.select(\"#\" + id)\n                .selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .attr(\"head-index\", (d, i) => i)\n                .selectAll(\"rect\")\n                .attr(\"x\", function () {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    return leftPos + boxOffsets(headIndex);\n                })\n                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n                .attr(\"width\", BOXWIDTH / activeHeads())\n                .attr(\"height\", BOXHEIGHT)\n                .style(\"opacity\", function (d) {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    if (config.headVis[headIndex])\n                        if (d) {\n                            return d[index];\n                        } else {\n                            return 0.0;\n                        }\n                    else\n                        return 0.0;\n                });\n        });\n\n        textContainer.on(\"mouseleave\", function () {\n\n            // Unhighlight selected token\n            d3.select(this).selectAll(\".background\")\n                .style(\"opacity\", 0.0);\n\n            // Reset visibility attributes for previously selected lines\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null) ;\n            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n\n            // Reset highlights superimposed over tokens\n            svg.selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .selectAll(\"rect\")\n                .style(\"opacity\", 0.0);\n        });\n    }\n\n    function renderAttention(svg, attention) {\n\n        // Remove previous dom elements\n        svg.select(\"#attention\").remove();\n\n        // Add new elements\n        svg.append(\"g\")\n            .attr(\"id\", \"attention\") // Container for all attention arcs\n            .selectAll(\".headAttention\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .classed(\"headAttention\", true) // Group attention arcs by head\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\".tokenAttention\")\n            .data(d => d)\n            .enter()\n            .append(\"g\")\n            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n            .attr(\"left-token-index\", (d, i) => i)\n            .selectAll(\"line\")\n            .data(d => d)\n            .enter()\n            .append(\"line\")\n            .attr(\"x1\", BOXWIDTH)\n            .attr(\"y1\", function () {\n                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n            })\n            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n            .attr(\"stroke-width\", 2)\n            .attr(\"stroke\", function () {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                return headColors(headIndex)\n            })\n            .attr(\"left-token-index\", function () {\n                return +this.parentNode.getAttribute(\"left-token-index\")\n            })\n            .attr(\"right-token-index\", (d, i) => i)\n        ;\n        updateAttention(svg)\n    }\n\n    function updateAttention(svg) {\n        svg.select(\"#attention\")\n            .selectAll(\"line\")\n            .attr(\"stroke-opacity\", function (d) {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                // If head is selected\n                if (config.headVis[headIndex]) {\n                    // Set opacity to attention weight divided by number of active heads\n                    return d / activeHeads()\n                } else {\n                    return 0.0;\n                }\n            })\n    }\n\n    function boxOffsets(i) {\n        const numHeadsAbove = config.headVis.reduce(\n            function (acc, val, cur) {\n                return val && cur < i ? acc + 1 : acc;\n            }, 0);\n        return numHeadsAbove * (BOXWIDTH / activeHeads());\n    }\n\n    function activeHeads() {\n        return config.headVis.reduce(function (acc, val) {\n            return val ? acc + 1 : acc;\n        }, 0);\n    }\n\n    function drawCheckboxes(top, svg) {\n        const checkboxContainer = svg.append(\"g\");\n        const checkbox = checkboxContainer.selectAll(\"rect\")\n            .data(config.headVis)\n            .enter()\n            .append(\"rect\")\n            .attr(\"fill\", (d, i) => headColors(i))\n            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n            .attr(\"y\", top)\n            .attr(\"width\", CHECKBOX_SIZE)\n            .attr(\"height\", CHECKBOX_SIZE);\n\n        function updateCheckboxes() {\n            checkboxContainer.selectAll(\"rect\")\n                .data(config.headVis)\n                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n        }\n\n        updateCheckboxes();\n\n        checkbox.on(\"click\", function (d, i) {\n            if (config.headVis[i] && activeHeads() === 1) return;\n            config.headVis[i] = !config.headVis[i];\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n\n        checkbox.on(\"dblclick\", function (d, i) {\n            // If we double click on the only active head then reset\n            if (config.headVis[i] && activeHeads() === 1) {\n                config.headVis = new Array(config.nHeads).fill(true);\n            } else {\n                config.headVis = new Array(config.nHeads).fill(false);\n                config.headVis[i] = true;\n            }\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n    }\n\n    function lighten(color) {\n        const c = d3.hsl(color);\n        const increment = (1 - c.l) * 0.6;\n        c.l += increment;\n        c.s -= increment;\n        return c;\n    }\n\n    function transpose(mat) {\n        return mat[0].map(function (col, i) {\n            return mat.map(function (row) {\n                return row[i];\n            });\n        });\n    }\n\n});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "input_text = \"The cat sat on the mat\"\n",
    "\n",
    "# 加载tokenizer和完整的预训练模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# 获取embed_dim\n",
    "embed_dim = pretrained_model.config.hidden_size\n",
    "print(f\"The embedding dimension is: {embed_dim}\")\n",
    "\n",
    "# 初始化你的SelfAttention模型\n",
    "model = MultiHeadAttention(embed_dim=embed_dim, num_heads=8)\n",
    "\n",
    "tokenized = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "with torch.no_grad():\n",
    "    inputs = pretrained_model(tokenized).last_hidden_state\n",
    "\n",
    "output, attention = model(inputs)  # Run model & Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized[0])  # Convert input ids to token strings\n",
    "\n",
    "attention = attention.unsqueeze(1).view(1, 1, 8, len(tokenized[0]), len(tokenized[0]))  # Self-attention only has one head\n",
    "head_view(attention, tokens)  # Display model view, attention dim: (batch_size, num_layers, num_heads, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 效率优化\n",
    "\n",
    "QKV 投影的时候，可以合并为一个大矩阵进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initialize the MultiHeadAttention module.\n",
    "        \n",
    "        Args:\n",
    "            embed_dim (int): The embedding dimension.\n",
    "            num_heads (int): The number of attention heads.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        \n",
    "        self.qkv_linear = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform multi-head attention operation.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of shape [batch_size, seq_len, embed_dim].\n",
    "            mask (Optional[torch.Tensor]): The mask tensor of shape [batch_size, seq_len, seq_len].\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: The output after multi-head attention operation.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Linear projections\n",
    "        QKV = self.qkv_linear(x)\n",
    "        Q, K, V = torch.split(QKV, 3, dim=-1)\n",
    "        \n",
    "        # Split into multiple heads\n",
    "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        att_weights = Q @ K.transpose(-2, -1) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        # Mask (opt.)\n",
    "        if mask is not None:\n",
    "            att_weights = att_weights.masked_fill(mask.unsqueeze(1) == 0, float('-inf'))\n",
    "        \n",
    "        # Softmax\n",
    "        attention = self.att_dropout(torch.softmax(att_weights, dim=-1))\n",
    "        \n",
    "        # Attention output\n",
    "        out = attention @ V\n",
    "        \n",
    "        # Concatenate heads\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)\n",
    "        \n",
    "        # Final linear projection\n",
    "        return self.out_proj(out), attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 现成的轮子\n",
    "\n",
    "- torch.nn.functional.scaled_dot_product_attention\n",
    "- torch.nn.MultiheadAttention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
