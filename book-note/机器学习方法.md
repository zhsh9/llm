# 监督学习

## ML和监督学习概论

### What is ML

基础知识

- ML：基于数据，构建概率模型，运行模型对数据进行预测与分析
- 学习：系统，通过执行某个过程，改进其性能
- 特点：建立在计算机&网络上的，数据驱动(对象)，对数据进行预测和分析(目的)，交叉学科
- 数据：文本，图形，视频，音频
- 方法：有监督学习，无监督学习，强化学习(reinforcement learning)

ML 三要素  
- 模型 model
- 策略 strategy
- 算法 algorithm

ML 可以概括为  
- 从给定的、有限的、用于学习的训练数据集合出发
- 假设数据是独立同分布产生的(每个样本都是相互独立&遵循相同的概率分布)
- 假设要学习的模型属于某个函数的集合(即假设空间 hypothesis space)
- 应用某个评价标准(evaluation critetion)，从假设空间中选出一个最优模型，使其对已知训练数据&未知测试数据有最优预测
- 最优模型的选取由算法实现

ML 的研究  
- 方法：开发新的方法
- 理论：探索ML方法的有效性&效率&基本理论问题
- 应用：垂直领域解决问题

计算机科学的三维组成  
- 系统
- 计算
- 信息(ML here)

### 机器学习的基本分类

#### 有监督学习

- 从标注数据中学习预测模型
- 本质：学习输入到输出的映射的统计规律
- 概念：输入空间，输出空间，实例，特征向量，特征空间；训练数据，测试数据，样本
- 假设：输入和输出的随机变量遵循联合概率分布 $P(X,Y)$ 表示分布(密度)函数
  - 学习过程中，假设的联合概率分布虽然存在，但是学习系统是不知道具体定义的
  - 训练&测试数据被看作是联合概率分布独立同分布产生的
- 目的：学习一个最好的输入到输出的映射(即，模型)
- 假设空间：由输入空间到输出空间的映射的集合
- 模型可以是概率模型or非概率模型，由条件概率分布 $P(X,Y)$ or 决策函数 $Y=f(X)$ 表示
- 预测：对具体的输入 $P(y|x)$ or $y=f(x)$

监督学习的过程：学习，预测

![Supervised Learning](./机器学习方法.assets/1.png)

#### 无监督学习

- 从无标注数据中学习预测模型
- 本质：学习数据中的统计规律或潜在结构
- 输入：特征向量；输出：对输入的分析结果，由输入的类别、转换或概率表示
- 作用：对数据的聚类，降维，概率估计
- 假设 $X$ 是输入空间 $Z$ 是隐式结构空间，要学习的模型可以表示为 ( $x\in X$ , $z\in Z$ )
  - 函数 $z=g(x)$
  - 条件概率分布 $P(z|x)$
  - 条件概率分布 $P(x|z)$

无监督学习的过程：学习，预测

![Unsupervised Learning](./机器学习方法.assets/2.png)

#### 强化学习

- 在与环境的连续互动中学习最优行为策略
- 假设智能系统与环境的互动基于马尔可夫决策过程(Markov decision process)
- 智能系统能观测到的是与环境互动得到的数据序列
- 本质：学习最优的序贯决策
- 强化学习的MDP：状态、奖励、动作序列上的随机过程，由四元组 $\langle S,A,P,r \rangle$ 组成

![Reinforcement Learning](./机器学习方法.assets/3.png)

[!] 这里还需要更深入的理解。

#### 半监督学习 & 主动学习

半监督学习  
- 利用大量未标注数据中的信息，辅助少量标注数据，进行监督
- 解决人工标注成本问题

主动学习  
- 机器不断主动给出实例让教师进行标注
- 利用标注数据让学生学习预测模型的机器学习问题

### 按模型分类

#### 概率与非概率模型

- 概率模型(Probabilistic model)
  - 决策树
  - 朴素贝尔斯
  - 隐马尔可夫模型
  - 条件随机场
  - 概率潜在语义分析
  - 潜在迪利克雷分类
  - 高斯混合模型
- 非概率模型(Non-probabilistic model)
  - 感知机
  - 支持向量机
  - k近邻
  - AdaBoost
  - k均值
  - 潜在语义分析
  - 神经网络
- 逻辑斯谛回归(both)

主要区别  
- 内在结构
- 概率模型可以表示为联合概率分布的形式，变量表示输入、输出、隐变量、参数
- 非概率模型不存在这样的联合概率分布

- 有监督学习
  - 概率模型: $P(y|x)$
  - 非概率模型: $y=f(x)$
- 无监督学习
  - 概率模型: $P(z|x)$ or $P(x|z)$
  - 非概率模型: $y=g(x)$

概率模型的推理，随机变量( $x$, $y$ )  
- 加法规则: $P(x)=\sum_y P(x,y)$
- 乘法规则: $P(x,y)=P(x)P(y|x)$

线性与非线性模型  
- 线性模型：感知机，线性支持向量机，k近邻，k均值，潜在语义分析
- 非线性模型：核函数支持向量机，AdaBoost，神经网络

参数化与非参数化模型  
- Parametric Model: 模型参数的维度固定，可以由有限维度参数完全刻画
- Non-parametric Model: 模型参数的维度不固定(无穷大)，随着训练数据量增加而增加

### 按算法分类

- 在线学习(online learning): 每次接受一个样本
- 批量学习(batch learning): 每次接受批量样本

![Online Learning](./机器学习方法.assets/4.png)

### 按技巧分类

#### 贝叶斯学习

- 在概率模型的学习和推理中，利用贝叶斯定义，计算在给定数据条件下模型的条件概率（后验概率），应用这个原理进行模型的估计，对数据的预测
- 将模型、未观测要素及其参数用变量表示，使用模型的先验分布

假设随机变量 D 表示数据，随机变量 $\theta$ 表示模型参数，根据贝叶斯定理，用以下公式计算后验概率

$$P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}$$

其中，

- $P(\theta)$ 先验概率
- $P(D|\theta)$ 似然函数

预测时，计算数据对后验概率分布的期望值：

$$P(x|D) = \int P(x|\theta, D)P(\theta|D)d\theta$$

贝叶斯估计和极大似然估计比较：

![Bayesian & Argmax](./机器学习方法.assets/5.png)

#### 核方法

Kernel method: 使用核函数表示和学习非线性模型
- 核方法可以把线性模型扩展到非线性模型学习
- 方法：显示地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中内积计算
- SVM：把输入空间的线性不可分问题转换为特征空间的线性可分问题
- 技巧：不显式定义映射，定义核函数

表示定理

假设 $x_1$ 和 $x_2$ 是输入空间的任意两个实例（向量），其内积是 $\langle x_1, x_2 \rangle$。假设从输入空间到特征空间的映射是 $\varphi$，那么 $x_1$ 和 $x_2$ 在特征空间的映像分别是 $\varphi(x_1)$ 和 $\varphi(x_2)$，它们的内积是 $\langle \varphi(x_1), \varphi(x_2) \rangle$。核方法直接在输入空间中定义核函数 $K(x_1, x_2)$，使其满足：

$$K(x_1, x_2) = \langle \varphi(x_1), \varphi(x_2) \rangle$$

这个表示定理给出了核函数成立的充要条件。核函数 $K(x_1, x_2)$ 实际上计算的是特征空间中两个向量的内积，但不需要显式地知道映射函数 $\varphi$ 的具体形式。

1. 避免了在高维特征空间中的直接计算
2. 允许在原始输入空间中进行计算，同时获得非线性变换的好处
3. 可以处理各种类型的数据，包括向量、字符串、图像等

### 机器学习方法三要素

$$方法 = 模型+策略+算法$$

#### 模型

函数集合定义:

- 决策函数

$$
F = \{f|Y=f_\theta(X), \theta \in R^n\}
$$

- 条件概率

$$
F = \{P|P_\theta(Y|X), \theta \in R^n\}
$$

#### 策略

预测的度量  
- 损失函数：度量模型一次预测的好坏
- 风险函数(期望损失)：度量模型平均意义下预测的好坏

经验风险|损失(empirical risk|loss)：模型关于训练数据集的平均损失

$$
R_emp(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i))
$$

结构风险|损失()：

$$
R_srm(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)) + \lambda J(f)
$$

基本策略  
- 经验风险最小化：样本容量足够大时，有很好的学习效果 e.g. 极大似然估计(maximum likelihood estimation)
- 结构风险最小化：在经验风险的基础上表示模型复杂度的正则化项(regulation)or惩罚项(penalty term)，防止过拟合 e.g. 最大后验概率估计

#### 算法

- 机器学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，选择计算方法求解最优模型
- ML归结为最优化问题，ML算法为最优化问题的算法
- 重点问题：如何找到全局最优解，并且求解过程非常高效

### 模型评估与模型选择

- 训练误差(调参优化) & 测试误差(泛化能力)
- 过拟合：所选模型的复杂度比真模型更高

### 正则化

正则化：模型复杂度的单调递增函数，可以是模型参数向量( $w$ )的范数

- 奥卡姆剃刀原理(Occam's razor)：在所有可能选择的模型中，能很好解释已知数据并十分简单才是最好的模型
- 贝叶斯估计角度：正则化项=模型的先验概率；复杂模型先验概率小，简单模型先验概率大

模型参数向量的范数选择

- L1范数

$$\lambda \frac{||w||^2}{2}$$

- L2范数

$$\lambda||w||_1$$

### 交叉验证

- 如果样本充足，切分为 training dataset, validation, test
- 交叉验证，重复使用数据

S-折交叉验证(S-fold cross validation)  
- 随机将数据集切分为S个互不相交、大小相同的子集
- 利用S-1个子集数据训练，1个子集测试模型
- 重复这个过程，选出S次评测中平均测试误差最小的模型

### 泛化能力

方法的泛化能力指的是该方法学习到的模型对未知数据的预测能力

泛化误差的定义：如果学到的模型是 $\hat{f}$，那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）：

$$R_{\exp}(\hat{f}) = E_P[L(Y, \hat{f}(X))]$$

$$= \int_{\mathcal{X}\times\mathcal{Y}} L(y, \hat{f}(x))P(x,y)dxdy \qquad (1.27)$$

在这个表达式中：
- $R_{\exp}(\hat{f})$ 表示期望风险（泛化误差）
- $E_P$ 表示关于联合分布 $P(X,Y)$ 的期望
- $L(Y, \hat{f}(X))$ 是损失函数
- $\mathcal{X}$ 和 $\mathcal{Y}$ 分别表示输入空间和输出空间
- $P(x,y)$ 是 $X$ 和 $Y$ 的联合概率密度函数

### 生成模型与判别模型

1. 生成模型 (Generative Model):
   - 生成模型学习联合概率分布 P(X,Y)，然后求出条件概率分布 P(Y|X) 作为预测模型。
   - 它能够描述给定输入 X 产生输出 Y 的生成关系。
   - 生成模型的例子包括朴素贝叶斯法和隐马尔可夫模型。
   - 特点：
     - 可以还原出联合概率分布 P(X,Y)
     - 学习收敛速度较快，尤其是在样本容量增加时
     - 可以处理存在隐变量的情况

2. 判别模型 (Discriminative Model):
   - 判别模型直接学习决策函数 f(X) 或条件概率分布 P(Y|X)。
   - 它关注于对给定输入 X，应该预测什么样的输出 Y。
   - 判别模型的例子包括k近邻法、感知机、逻辑斯蒂回归模型、最大熵模型、支持向量机等。
   - 特点：
     - 直接面对预测，往往学习的精确率更高
     - 可以对数据进行各种程度的抽象，定义特征并使用特征
     - 可以简化学习问题

### 有监督学习应用

- 分类问题: $P(Y|X)$ or $Y=f(X)$
  - 分类情况: TP, FN, FP, TN
  - 性能指标: accuracy, precision, recall, f1
- 标注问题: $P(Y^{1},Y^{2},\cdots,Y^{n})|X^{1},X^{2},\cdots,X^{n}$
  - 指标和分类问题类似
  - 常用的方法：隐马尔可夫模型，条件随机场
- 回归问题: $Y=f(X)$ 等价于函数拟合，选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据
  - 常用损失函数：平凡损失函数；问题可以由由最小二乘法求解

## 感知机 Perceptron

- 在 1957 年由 Rosenblatt 提出
- 二分类线性分类模型，输入为特征向量，输出为实例的类别
- 感知机学习将实例划分为正负两类的线性划分的分离超平面，属于判别模型
- 使用基于误分类的损失函数，梯度下降法对损失函数最小化

### 感知机模型

假设输入空间（特征空间）是 $X \subseteq R^n$, 输出空间是 $Y=\{+1,-1\}$. 输入 $x \in X$ 表示实例的特征向量,对应于输入空间（特征空间）的点;输出 $y \in Y$ 表示实例的类别. 由输入空间到输出空间的如下函数

$$
f(x) = \text{sign}(w \cdot x + b)
$$

称为感知机. 其中, $w$ 和 $b$ 为感知机模型参数, $w \in R^n$ 叫作权值(weight)或权值向量(weight vector), $b \in R$ 叫作偏置(bias), $w \cdot x$ 表示 $w$ 和 $x$ 的内积. sign 是符号函数, 即

$$
\text{sign}(x) = \begin{cases}
+1, & x \geq 0 \\
-1, & x < 0
\end{cases}
$$

感知机模型的假设空间是特征空间中所有的线性分类模型(linear classification model)，即函数集合 $\{f|f(x)=w\cdot x+b\}$

感知机的集合解释：线性方程 $w\cdot x+b=0$ 对应于特征空间 $R^n$ 中的一个超平面(分离超平面 separating hyperplane) $S$ 其中 $w$ 是超平面的法向量 $b$ 是截距，空间划分为两个部分分别为正负类。

### 感知机学习策略

- 数据集线性可分: 存在某个超平面，完全正确划分两类到超平面两侧
- 学习策略，定义经验损失函数并且最小化: 选择的损失函数要是参数 $w, b$ 的连续可导
  - 即，误分类点到超平面 S 的总距离

假设 S 的误分类点集合为 M，所有误分类点到 S 的总距离为

$$
-\frac{1}{||w||}\sum_{x_i \in M}y_i(w \cdot x_i+b)
$$

"函数间隔"是机器学习中的一个重要概念，尤其在支持向量机(SVM)中常见。它衡量的是模型对某个样本点分类的确信程度。函数间隔的绝对值越大，表示模型对这个样本分类越有信心。

简单来说，这个公式计算出的值反映了样本点到决策边界的距离，同时考虑了样本的真实类别。正值表示分类正确，负值表示分类错误，绝对值大小表示分类的确信度。这个概念在优化分类模型时非常重要，因为我们通常希望最大化所有样本点的函数间隔，以获得更好的分类效果。

因此，感知机 $sign(w\cdot x+b)$ 学习的损失函数定义为

$$
L(w,b)=-\sum_{x_i\in M}y_i(w\cdot x_i+b)
$$

感知机的学习策略：在假设空间中选取是损失函数最小的模型参数 $w,b$ 

### 感知机学习算法

训练数据集

$$
T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}
$$

其中, $x_i\in X=R^n$, $y_i\in Y=\{-1,+1\}$, $i=1,2,\cdots,N$

#### 感知机学习算法的原始形式

学习算法是误分类驱动的，采用 SGD: 任取一个超平面 $w_0,b_0$ 使用 SGD 不断极小化目标函数；**注意**：极小化过程不是一次使 M 中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降

假设误分类点集合 M 是固定的，L的梯度

$$
\triangledown_w L(w,b) = -\sum_{x_i\in M}y_ix_i  \\
\triangledown_b L(w,b) = -\sum_{x_i\in M}y_i
$$

随机选取一个误分类点 $(x_i,y_i)$ 对 $w,b$ 进行更新

$$
w \leftarrow w + \eta y_ix_i  \\
b \leftarrow b + \eta y_i
$$

算法伪代码如下:

> 输入: 训练数据集 T = {(x1, y1), (x2, y2), ..., (xN, yN)}, 其中 xi ∈ X = R^n, yi ∈ Y = {-1, +1}, i = 1, 2, ..., N; 学习率 η (0 < η ≤ 1)。
> 输出: w, b; 感知机模型 f(x) = sign(w · x + b)。
> 算法步骤:
> 1. 选取初值 w0, b0;
> 2. 在训练集中选取数据 (xi, yi);
> 3. 如果 yi(w · xi + b) ≤ 0, 则
>    w ← w + ηyixi
>    b ← b + ηyi
> 4. 转至步骤 (2), 直至训练集中没有误分类点。

#### 算法的收敛性

证明，对于线性可分数据集，感知机学习算法原始形式收敛（经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面）

**定理 2.1 (Novikoff)**

设训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$ 是线性可分的，其中 $x_i \in \mathcal{X} = \mathbb{R}^n$, $y_i \in \mathcal{Y} = \{-1,+1\}$, $i = 1, 2, \ldots, N$, 则

(1) 存在满足条件 $\|\hat{w}_{opt}\| = 1$ 的超平面 $\hat{w}_{opt} \cdot \hat{x} = w_{opt} \cdot x + b_{opt} = 0$ 将训练数据集完全正确分开；且存在 $\gamma > 0$, 对所有 $i = 1, 2, \ldots, N$, 有

$$
y_i(\hat{w}_{opt} \cdot \hat{x}_i) = y_i(w_{opt} \cdot x_i + b_{opt}) \geq \gamma
$$

(2) 令 $R = \max_{1\leq i\leq N} \|\hat{x}_i\|$, 则感知机算法 2.1 在训练数据集上的误分类次数 $k$ 满足不等式

$$
k \leq \left(\frac{R}{\gamma}\right)^2
$$

上述定理说明，误分类次数 k 是有上界的，即当数据线性可分，感知机学习算法原始形式迭代是收敛的；但是存在许多解，依赖于初值的选择和迭代过程中误分类点的选择损失。

为得到唯一的超平面，需要对分离超平面增加约束条件（线性支持向量机）；当训练集线性不可分时，感知机学习算法不收敛，迭代结果会震荡

#### 感知机学习算法的对偶形式

对偶形式的想法是：将 $w,b$ 表示为数据 $(x_i,y_i)$ 的线性组合形式，通过求解系数而求得 $w,b$ 。对误分类点通过梯度下降逐步修改模型参数，设修改 n 次，则参数的增量为 $\alpha_i y_ix_i, \alpha_i y_i$ 在这里 $\alpha_i=n_i\eta$ ，最后学习到的参数可以表示为

$$
w=\sum_{i=1}^N \alpha_i y_ix_i  \\
b=\sum_{i=1}^N \alpha_i y_i
$$

![感知机学习算法的对偶形式](./机器学习方法.assets/6.png)

### 感知机相关问题

> Minsky 和 Papert 指出：感知机因为是线性模型，所以不能表示复杂的函数（例如XOR），为什么？

XOR 的数据集线性不可分

> **定理**: 样本集线性可分的充分必要条件是正实例点集所构成的凸壳与负实例点集所构成的凸壳互不相交。

凸壳 (Convex Hull) 的定义：
设集合 $S \subset \mathbb{R}^n$ 是由 $\mathbb{R}^n$ 中的 $k$ 个点所组成的集合，即 $S = \{x_1, x_2, \cdots, x_k\}$，定义 $S$ 的凸壳 $conv(S)$ 为：

$$
conv(S) = \left\{x = \sum_{i=1}^k \lambda_i x_i \bigg| \sum_{i=1}^k \lambda_i = 1, \lambda_i \geq 0, i = 1,2,\cdots,k \right\}
$$

证明:

1. 充分性：
   假设正实例点集的凸壳与负实例点集的凸壳互不相交。
   - 根据凸集分离定理，存在一个超平面能够将这两个凸壳分开。
   - 这个超平面就能够将正实例和负实例完全分开。
   - 因此，样本集是线性可分的。

2. 必要性：
   假设样本集是线性可分的。
   - 存在一个超平面 $w^T x + b = 0$ 能够将正实例和负实例完全分开。
   - 对于任意正实例 $x_+$，有 $w^T x_+ + b > 0$。
   - 对于任意负实例 $x_-$，有 $w^T x_- + b < 0$。
   - 假设正实例凸壳中的点 $p = \sum_{i=1}^m \alpha_i x_i^+$，其中 $\sum_{i=1}^m \alpha_i = 1, \alpha_i \geq 0$。
   - 则有：
     $w^T p + b = w^T (\sum_{i=1}^m \alpha_i x_i^+) + b = \sum_{i=1}^m \alpha_i (w^T x_i^+ + b) > 0$
   - 同理，对于负实例凸壳中的任意点 $q$，有 $w^T q + b < 0$。
   - 这说明正实例的凸壳完全位于超平面的一侧，负实例的凸壳完全位于超平面的另一侧。
   - 因此，两个凸壳互不相交。

综上所述，定理得证。

## k 近邻

KNN 是一种分类与回归方法。三要素为：

- k 值的选择
- 距离度量
- 分类决策

### KNN 算法

KNN 没有显示的学习过程

![KNN](./机器学习方法.assets/7.png)

### KNN 模型

根据三要素（训练集、距离度量、k值、分类决策规则）确定 KNN 模型后，相当于将特征空间划分为子空间，确定子空间里的每个点所属的类

单元：对每个训练实例点，距离该点比其他点更近的所有点组成的区域；所有训练实例点的单元构成对特征空间的一个划分

距离度量：两个实例点相似程度  
- $L_p$ 距离
- p=1，曼哈顿距离 Manhattan distance
- p=2，欧氏距离 Euclidean distance
- p=inf，各个坐标最大值

![L_p距离间的关系](./机器学习方法.assets/8.png)

k 值的选择  
- k 较小：增大学习估计误差，减少学习近似误差，模型更复杂，容易过拟合
- k 较大：减少学习估计误差，增大学习近似误差，模型更简单，容易欠拟合

分类决策规则  
- 多数表决规则 majority voting rule
- 多数表决规则等价于经验风险最小化

### KNN 的实现: kd Tree

KNN 主要问题：如何对训练数据进行快速 k 近邻搜索

## 朴素贝叶斯

## 决策树

## 逻辑斯谛回归与最大熵模型

## 支持向量机

## Boosting

## EM 算法及其推广

## 隐马尔可夫模型

## 条件随机场

## 监督学习总结

# 无监督学习

# 深度学习
