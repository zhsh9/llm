- [监督学习](#监督学习)
  - [ML和监督学习概论](#ml和监督学习概论)
    - [What is ML](#what-is-ml)
    - [机器学习的基本分类](#机器学习的基本分类)
      - [有监督学习](#有监督学习)
      - [无监督学习](#无监督学习)
      - [强化学习](#强化学习)
      - [半监督学习 \& 主动学习](#半监督学习--主动学习)
    - [按模型分类](#按模型分类)
      - [概率与非概率模型](#概率与非概率模型)
    - [按算法分类](#按算法分类)
    - [按技巧分类](#按技巧分类)
      - [贝叶斯学习](#贝叶斯学习)
      - [核方法](#核方法)
    - [机器学习方法三要素](#机器学习方法三要素)
      - [模型](#模型)
      - [策略](#策略)
      - [算法](#算法)
    - [模型评估与模型选择](#模型评估与模型选择)
    - [正则化](#正则化)
    - [交叉验证](#交叉验证)
    - [泛化能力](#泛化能力)
    - [生成模型与判别模型](#生成模型与判别模型)
    - [有监督学习应用](#有监督学习应用)
  - [感知机 Perceptron](#感知机-perceptron)
    - [感知机模型](#感知机模型)
    - [感知机学习策略](#感知机学习策略)
    - [感知机学习算法](#感知机学习算法)
      - [感知机学习算法的原始形式](#感知机学习算法的原始形式)
      - [算法的收敛性](#算法的收敛性)
      - [感知机学习算法的对偶形式](#感知机学习算法的对偶形式)
    - [感知机相关问题](#感知机相关问题)
  - [k 近邻](#k-近邻)
    - [KNN 算法](#knn-算法)
    - [KNN 模型](#knn-模型)
    - [KNN 的实现: kd Tree](#knn-的实现-kd-tree)
  - [朴素贝叶斯](#朴素贝叶斯)
    - [朴素贝叶斯基础](#朴素贝叶斯基础)
    - [极大似然估计](#极大似然估计)
    - [朴素贝叶斯算法](#朴素贝叶斯算法)
    - [贝叶斯估计](#贝叶斯估计)
  - [决策树](#决策树)
    - [决策树的学习](#决策树的学习)
    - [信息增益: 熵(Entropy)](#信息增益-熵entropy)
    - [决策树的生成](#决策树的生成)
      - [ID3](#id3)
      - [C4.5](#c45)
  - [逻辑斯谛回归与最大熵模型](#逻辑斯谛回归与最大熵模型)
  - [支持向量机](#支持向量机)
  - [Boosting](#boosting)
  - [EM 算法及其推广](#em-算法及其推广)
  - [隐马尔可夫模型](#隐马尔可夫模型)
  - [条件随机场](#条件随机场)
  - [监督学习总结](#监督学习总结)
- [无监督学习](#无监督学习-1)
- [深度学习](#深度学习)
  - [前馈神经网络](#前馈神经网络)
    - [MLP定义](#mlp定义)
    - [MLP的表示能力](#mlp的表示能力)
    - [MLP学习算法](#mlp学习算法)
      - [一般形式](#一般形式)
      - [回归的形式](#回归的形式)
      - [二分类的形式](#二分类的形式)
      - [多分类的形式](#多分类的形式)
    - [MLP学习的优化算法](#mlp学习的优化算法)
    - [反向传播算法](#反向传播算法)
    - [计算图上的实现](#计算图上的实现)
    - [算法实现技巧](#算法实现技巧)
    - [正则化](#正则化-1)
  - [卷积神经网络](#卷积神经网络)
  - [循环神经网络](#循环神经网络)
  - [序列到序列模型](#序列到序列模型)
  - [预训练语言模型](#预训练语言模型)
  - [生成对抗网络](#生成对抗网络)

---

# 监督学习

## ML和监督学习概论

### What is ML

基础知识

- ML：基于数据，构建概率模型，运行模型对数据进行预测与分析
- 学习：系统，通过执行某个过程，改进其性能
- 特点：建立在计算机&网络上的，数据驱动(对象)，对数据进行预测和分析(目的)，交叉学科
- 数据：文本，图形，视频，音频
- 方法：有监督学习，无监督学习，强化学习(reinforcement learning)

ML 三要素  
- 模型 model
- 策略 strategy
- 算法 algorithm

ML 可以概括为  
- 从给定的、有限的、用于学习的训练数据集合出发
- 假设数据是独立同分布产生的(每个样本都是相互独立&遵循相同的概率分布)
- 假设要学习的模型属于某个函数的集合(即假设空间 hypothesis space)
- 应用某个评价标准(evaluation critetion)，从假设空间中选出一个最优模型，使其对已知训练数据&未知测试数据有最优预测
- 最优模型的选取由算法实现

ML 的研究  
- 方法：开发新的方法
- 理论：探索ML方法的有效性&效率&基本理论问题
- 应用：垂直领域解决问题

计算机科学的三维组成  
- 系统
- 计算
- 信息(ML here)

### 机器学习的基本分类

#### 有监督学习

- 从标注数据中学习预测模型
- 本质：学习输入到输出的映射的统计规律
- 概念：输入空间，输出空间，实例，特征向量，特征空间；训练数据，测试数据，样本
- 假设：输入和输出的随机变量遵循联合概率分布 $P(X,Y)$ 表示分布(密度)函数
  - 学习过程中，假设的联合概率分布虽然存在，但是学习系统是不知道具体定义的
  - 训练&测试数据被看作是联合概率分布独立同分布产生的
- 目的：学习一个最好的输入到输出的映射(即，模型)
- 假设空间：由输入空间到输出空间的映射的集合
- 模型可以是概率模型or非概率模型，由条件概率分布 $P(X,Y)$ or 决策函数 $Y=f(X)$ 表示
- 预测：对具体的输入 $P(y|x)$ or $y=f(x)$

监督学习的过程：学习，预测

![Supervised Learning](./机器学习方法.assets/1.png)

#### 无监督学习

- 从无标注数据中学习预测模型
- 本质：学习数据中的统计规律或潜在结构
- 输入：特征向量；输出：对输入的分析结果，由输入的类别、转换或概率表示
- 作用：对数据的聚类，降维，概率估计
- 假设 $X$ 是输入空间 $Z$ 是隐式结构空间，要学习的模型可以表示为 ( $x\in X$ , $z\in Z$ )
  - 函数 $z=g(x)$
  - 条件概率分布 $P(z|x)$
  - 条件概率分布 $P(x|z)$

无监督学习的过程：学习，预测

![Unsupervised Learning](./机器学习方法.assets/2.png)

#### 强化学习

- 在与环境的连续互动中学习最优行为策略
- 假设智能系统与环境的互动基于马尔可夫决策过程(Markov decision process)
- 智能系统能观测到的是与环境互动得到的数据序列
- 本质：学习最优的序贯决策
- 强化学习的MDP：状态、奖励、动作序列上的随机过程，由四元组 $\langle S,A,P,r \rangle$ 组成

![Reinforcement Learning](./机器学习方法.assets/3.png)

[!] 这里还需要更深入的理解。

#### 半监督学习 & 主动学习

半监督学习  
- 利用大量未标注数据中的信息，辅助少量标注数据，进行监督
- 解决人工标注成本问题

主动学习  
- 机器不断主动给出实例让教师进行标注
- 利用标注数据让学生学习预测模型的机器学习问题

### 按模型分类

#### 概率与非概率模型

- 概率模型(Probabilistic model)
  - 决策树
  - 朴素贝尔斯
  - 隐马尔可夫模型
  - 条件随机场
  - 概率潜在语义分析
  - 潜在迪利克雷分类
  - 高斯混合模型
- 非概率模型(Non-probabilistic model)
  - 感知机
  - 支持向量机
  - k近邻
  - AdaBoost
  - k均值
  - 潜在语义分析
  - 神经网络
- 逻辑斯谛回归(both)

主要区别  
- 内在结构
- 概率模型可以表示为联合概率分布的形式，变量表示输入、输出、隐变量、参数
- 非概率模型不存在这样的联合概率分布

- 有监督学习
  - 概率模型: $P(y|x)$
  - 非概率模型: $y=f(x)$
- 无监督学习
  - 概率模型: $P(z|x)$ or $P(x|z)$
  - 非概率模型: $y=g(x)$

概率模型的推理，随机变量( $x$, $y$ )  
- 加法规则: $P(x)=\sum_y P(x,y)$
- 乘法规则: $P(x,y)=P(x)P(y|x)$

线性与非线性模型  
- 线性模型：感知机，线性支持向量机，k近邻，k均值，潜在语义分析
- 非线性模型：核函数支持向量机，AdaBoost，神经网络

参数化与非参数化模型  
- Parametric Model: 模型参数的维度固定，可以由有限维度参数完全刻画
- Non-parametric Model: 模型参数的维度不固定(无穷大)，随着训练数据量增加而增加

### 按算法分类

- 在线学习(online learning): 每次接受一个样本
- 批量学习(batch learning): 每次接受批量样本

![Online Learning](./机器学习方法.assets/4.png)

### 按技巧分类

#### 贝叶斯学习

- 在概率模型的学习和推理中，利用贝叶斯定义，计算在给定数据条件下模型的条件概率（后验概率），应用这个原理进行模型的估计，对数据的预测
- 将模型、未观测要素及其参数用变量表示，使用模型的先验分布

假设随机变量 D 表示数据，随机变量 $\theta$ 表示模型参数，根据贝叶斯定理，用以下公式计算后验概率

$$P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}$$

其中，

- $P(\theta)$ 先验概率
- $P(D|\theta)$ 似然函数

预测时，计算数据对后验概率分布的期望值：

$$P(x|D) = \int P(x|\theta, D)P(\theta|D)d\theta$$

贝叶斯估计和极大似然估计比较：

![Bayesian & Argmax](./机器学习方法.assets/5.png)

#### 核方法

Kernel method: 使用核函数表示和学习非线性模型
- 核方法可以把线性模型扩展到非线性模型学习
- 方法：显示地定义从输入空间（低维空间）到特征空间（高维空间）的映射，在特征空间中内积计算
- SVM：把输入空间的线性不可分问题转换为特征空间的线性可分问题
- 技巧：不显式定义映射，定义核函数

表示定理

假设 $x_1$ 和 $x_2$ 是输入空间的任意两个实例（向量），其内积是 $\langle x_1, x_2 \rangle$。假设从输入空间到特征空间的映射是 $\varphi$，那么 $x_1$ 和 $x_2$ 在特征空间的映像分别是 $\varphi(x_1)$ 和 $\varphi(x_2)$，它们的内积是 $\langle \varphi(x_1), \varphi(x_2) \rangle$。核方法直接在输入空间中定义核函数 $K(x_1, x_2)$，使其满足：

$$K(x_1, x_2) = \langle \varphi(x_1), \varphi(x_2) \rangle$$

这个表示定理给出了核函数成立的充要条件。核函数 $K(x_1, x_2)$ 实际上计算的是特征空间中两个向量的内积，但不需要显式地知道映射函数 $\varphi$ 的具体形式。

1. 避免了在高维特征空间中的直接计算
2. 允许在原始输入空间中进行计算，同时获得非线性变换的好处
3. 可以处理各种类型的数据，包括向量、字符串、图像等

### 机器学习方法三要素

$$方法 = 模型+策略+算法$$

#### 模型

函数集合定义:

- 决策函数

$$
F = \{f|Y=f_\theta(X), \theta \in R^n\}
$$

- 条件概率

$$
F = \{P|P_\theta(Y|X), \theta \in R^n\}
$$

#### 策略

预测的度量  
- 损失函数：度量模型一次预测的好坏
- 风险函数(期望损失)：度量模型平均意义下预测的好坏

经验风险|损失(empirical risk|loss)：模型关于训练数据集的平均损失

$$
R_emp(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i))
$$

结构风险|损失()：

$$
R_srm(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)) + \lambda J(f)
$$

基本策略  
- 经验风险最小化：样本容量足够大时，有很好的学习效果 e.g. 极大似然估计(maximum likelihood estimation)
- 结构风险最小化：在经验风险的基础上表示模型复杂度的正则化项(regulation)or惩罚项(penalty term)，防止过拟合 e.g. 最大后验概率估计

#### 算法

- 机器学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，选择计算方法求解最优模型
- ML归结为最优化问题，ML算法为最优化问题的算法
- 重点问题：如何找到全局最优解，并且求解过程非常高效

### 模型评估与模型选择

- 训练误差(调参优化) & 测试误差(泛化能力)
- 过拟合：所选模型的复杂度比真模型更高

### 正则化

正则化：模型复杂度的单调递增函数，可以是模型参数向量( $w$ )的范数

- 奥卡姆剃刀原理(Occam's razor)：在所有可能选择的模型中，能很好解释已知数据并十分简单才是最好的模型
- 贝叶斯估计角度：正则化项=模型的先验概率；复杂模型先验概率小，简单模型先验概率大

模型参数向量的范数选择

- L1范数

$$\lambda \frac{||w||^2}{2}$$

- L2范数

$$\lambda||w||_1$$

### 交叉验证

- 如果样本充足，切分为 training dataset, validation, test
- 交叉验证，重复使用数据

S-折交叉验证(S-fold cross validation)  
- 随机将数据集切分为S个互不相交、大小相同的子集
- 利用S-1个子集数据训练，1个子集测试模型
- 重复这个过程，选出S次评测中平均测试误差最小的模型

### 泛化能力

方法的泛化能力指的是该方法学习到的模型对未知数据的预测能力

泛化误差的定义：如果学到的模型是 $\hat{f}$，那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）：

$$R_{\exp}(\hat{f}) = E_P[L(Y, \hat{f}(X))]$$

$$= \int_{\mathcal{X}\times\mathcal{Y}} L(y, \hat{f}(x))P(x,y)dxdy \qquad (1.27)$$

在这个表达式中：
- $R_{\exp}(\hat{f})$ 表示期望风险（泛化误差）
- $E_P$ 表示关于联合分布 $P(X,Y)$ 的期望
- $L(Y, \hat{f}(X))$ 是损失函数
- $\mathcal{X}$ 和 $\mathcal{Y}$ 分别表示输入空间和输出空间
- $P(x,y)$ 是 $X$ 和 $Y$ 的联合概率密度函数

### 生成模型与判别模型

1. 生成模型 (Generative Model):
   - 生成模型学习联合概率分布 P(X,Y)，然后求出条件概率分布 P(Y|X) 作为预测模型。
   - 它能够描述给定输入 X 产生输出 Y 的生成关系。
   - 生成模型的例子包括朴素贝叶斯法和隐马尔可夫模型。
   - 特点：
     - 可以还原出联合概率分布 P(X,Y)
     - 学习收敛速度较快，尤其是在样本容量增加时
     - 可以处理存在隐变量的情况

2. 判别模型 (Discriminative Model):
   - 判别模型直接学习决策函数 f(X) 或条件概率分布 P(Y|X)。
   - 它关注于对给定输入 X，应该预测什么样的输出 Y。
   - 判别模型的例子包括k近邻法、感知机、逻辑斯蒂回归模型、最大熵模型、支持向量机等。
   - 特点：
     - 直接面对预测，往往学习的精确率更高
     - 可以对数据进行各种程度的抽象，定义特征并使用特征
     - 可以简化学习问题

### 有监督学习应用

- 分类问题: $P(Y|X)$ or $Y=f(X)$
  - 分类情况: TP, FN, FP, TN
  - 性能指标: accuracy, precision, recall, f1
- 标注问题: $P(Y^{1},Y^{2},\cdots,Y^{n})|X^{1},X^{2},\cdots,X^{n}$
  - 指标和分类问题类似
  - 常用的方法：隐马尔可夫模型，条件随机场
- 回归问题: $Y=f(X)$ 等价于函数拟合，选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据
  - 常用损失函数：平凡损失函数；问题可以由由最小二乘法求解

## 感知机 Perceptron

- 在 1957 年由 Rosenblatt 提出
- 二分类线性分类模型，输入为特征向量，输出为实例的类别
- 感知机学习将实例划分为正负两类的线性划分的分离超平面，属于判别模型
- 使用基于误分类的损失函数，梯度下降法对损失函数最小化

### 感知机模型

假设输入空间（特征空间）是 $X \subseteq R^n$, 输出空间是 $Y=\{+1,-1\}$. 输入 $x \in X$ 表示实例的特征向量,对应于输入空间（特征空间）的点;输出 $y \in Y$ 表示实例的类别. 由输入空间到输出空间的如下函数

$$
f(x) = \text{sign}(w \cdot x + b)
$$

称为感知机. 其中, $w$ 和 $b$ 为感知机模型参数, $w \in R^n$ 叫作权值(weight)或权值向量(weight vector), $b \in R$ 叫作偏置(bias), $w \cdot x$ 表示 $w$ 和 $x$ 的内积. sign 是符号函数, 即

$$
\text{sign}(x) = \begin{cases}
+1, & x \geq 0 \\
-1, & x < 0
\end{cases}
$$

感知机模型的假设空间是特征空间中所有的线性分类模型(linear classification model)，即函数集合 $\{f|f(x)=w\cdot x+b\}$

感知机的集合解释：线性方程 $w\cdot x+b=0$ 对应于特征空间 $R^n$ 中的一个超平面(分离超平面 separating hyperplane) $S$ 其中 $w$ 是超平面的法向量 $b$ 是截距，空间划分为两个部分分别为正负类。

### 感知机学习策略

- 数据集线性可分: 存在某个超平面，完全正确划分两类到超平面两侧
- 学习策略，定义经验损失函数并且最小化: 选择的损失函数要是参数 $w, b$ 的连续可导
  - 即，误分类点到超平面 S 的总距离

假设 S 的误分类点集合为 M，所有误分类点到 S 的总距离为

$$
-\frac{1}{||w||}\sum_{x_i \in M}y_i(w \cdot x_i+b)
$$

"函数间隔"是机器学习中的一个重要概念，尤其在支持向量机(SVM)中常见。它衡量的是模型对某个样本点分类的确信程度。函数间隔的绝对值越大，表示模型对这个样本分类越有信心。

简单来说，这个公式计算出的值反映了样本点到决策边界的距离，同时考虑了样本的真实类别。正值表示分类正确，负值表示分类错误，绝对值大小表示分类的确信度。这个概念在优化分类模型时非常重要，因为我们通常希望最大化所有样本点的函数间隔，以获得更好的分类效果。

因此，感知机 $sign(w\cdot x+b)$ 学习的损失函数定义为

$$
L(w,b)=-\sum_{x_i\in M}y_i(w\cdot x_i+b)
$$

感知机的学习策略：在假设空间中选取是损失函数最小的模型参数 $w,b$ 

### 感知机学习算法

训练数据集

$$
T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}
$$

其中, $x_i\in X=R^n$, $y_i\in Y=\{-1,+1\}$, $i=1,2,\cdots,N$

#### 感知机学习算法的原始形式

学习算法是误分类驱动的，采用 SGD: 任取一个超平面 $w_0,b_0$ 使用 SGD 不断极小化目标函数；**注意**：极小化过程不是一次使 M 中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降

假设误分类点集合 M 是固定的，L的梯度

$$
\triangledown_w L(w,b) = -\sum_{x_i\in M}y_ix_i  \\
\triangledown_b L(w,b) = -\sum_{x_i\in M}y_i
$$

随机选取一个误分类点 $(x_i,y_i)$ 对 $w,b$ 进行更新

$$
w \leftarrow w + \eta y_ix_i  \\
b \leftarrow b + \eta y_i
$$

算法伪代码如下:

> 输入: 训练数据集 T = {(x1, y1), (x2, y2), ..., (xN, yN)}, 其中 xi ∈ X = R^n, yi ∈ Y = {-1, +1}, i = 1, 2, ..., N; 学习率 η (0 < η ≤ 1)。
> 输出: w, b; 感知机模型 f(x) = sign(w · x + b)。
> 算法步骤:
> 1. 选取初值 w0, b0;
> 2. 在训练集中选取数据 (xi, yi);
> 3. 如果 yi(w · xi + b) ≤ 0, 则
>    w ← w + ηyixi
>    b ← b + ηyi
> 4. 转至步骤 (2), 直至训练集中没有误分类点。

#### 算法的收敛性

证明，对于线性可分数据集，感知机学习算法原始形式收敛（经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面）

**定理 2.1 (Novikoff)**

设训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$ 是线性可分的，其中 $x_i \in \mathcal{X} = \mathbb{R}^n$, $y_i \in \mathcal{Y} = \{-1,+1\}$, $i = 1, 2, \ldots, N$, 则

(1) 存在满足条件 $\|\hat{w}_{opt}\| = 1$ 的超平面 $\hat{w}_{opt} \cdot \hat{x} = w_{opt} \cdot x + b_{opt} = 0$ 将训练数据集完全正确分开；且存在 $\gamma > 0$, 对所有 $i = 1, 2, \ldots, N$, 有

$$
y_i(\hat{w}_{opt} \cdot \hat{x}_i) = y_i(w_{opt} \cdot x_i + b_{opt}) \geq \gamma
$$

(2) 令 $R = \max_{1\leq i\leq N} \|\hat{x}_i\|$, 则感知机算法 2.1 在训练数据集上的误分类次数 $k$ 满足不等式

$$
k \leq \left(\frac{R}{\gamma}\right)^2
$$

上述定理说明，误分类次数 k 是有上界的，即当数据线性可分，感知机学习算法原始形式迭代是收敛的；但是存在许多解，依赖于初值的选择和迭代过程中误分类点的选择损失。

为得到唯一的超平面，需要对分离超平面增加约束条件（线性支持向量机）；当训练集线性不可分时，感知机学习算法不收敛，迭代结果会震荡

#### 感知机学习算法的对偶形式

对偶形式的想法是：将 $w,b$ 表示为数据 $(x_i,y_i)$ 的线性组合形式，通过求解系数而求得 $w,b$ 。对误分类点通过梯度下降逐步修改模型参数，设修改 n 次，则参数的增量为 $\alpha_i y_ix_i, \alpha_i y_i$ 在这里 $\alpha_i=n_i\eta$ ，最后学习到的参数可以表示为

$$
w=\sum_{i=1}^N \alpha_i y_ix_i  \\
b=\sum_{i=1}^N \alpha_i y_i
$$

![感知机学习算法的对偶形式](./机器学习方法.assets/6.png)

### 感知机相关问题

> Minsky 和 Papert 指出：感知机因为是线性模型，所以不能表示复杂的函数（例如XOR），为什么？

XOR 的数据集线性不可分

> **定理**: 样本集线性可分的充分必要条件是正实例点集所构成的凸壳与负实例点集所构成的凸壳互不相交。

凸壳 (Convex Hull) 的定义：
设集合 $S \subset \mathbb{R}^n$ 是由 $\mathbb{R}^n$ 中的 $k$ 个点所组成的集合，即 $S = \{x_1, x_2, \cdots, x_k\}$，定义 $S$ 的凸壳 $conv(S)$ 为：

$$
conv(S) = \left\{x = \sum_{i=1}^k \lambda_i x_i \bigg| \sum_{i=1}^k \lambda_i = 1, \lambda_i \geq 0, i = 1,2,\cdots,k \right\}
$$

证明:

1. 充分性：
   假设正实例点集的凸壳与负实例点集的凸壳互不相交。
   - 根据凸集分离定理，存在一个超平面能够将这两个凸壳分开。
   - 这个超平面就能够将正实例和负实例完全分开。
   - 因此，样本集是线性可分的。

2. 必要性：
   假设样本集是线性可分的。
   - 存在一个超平面 $w^T x + b = 0$ 能够将正实例和负实例完全分开。
   - 对于任意正实例 $x_+$，有 $w^T x_+ + b > 0$。
   - 对于任意负实例 $x_-$，有 $w^T x_- + b < 0$。
   - 假设正实例凸壳中的点 $p = \sum_{i=1}^m \alpha_i x_i^+$，其中 $\sum_{i=1}^m \alpha_i = 1, \alpha_i \geq 0$。
   - 则有：
     $w^T p + b = w^T (\sum_{i=1}^m \alpha_i x_i^+) + b = \sum_{i=1}^m \alpha_i (w^T x_i^+ + b) > 0$
   - 同理，对于负实例凸壳中的任意点 $q$，有 $w^T q + b < 0$。
   - 这说明正实例的凸壳完全位于超平面的一侧，负实例的凸壳完全位于超平面的另一侧。
   - 因此，两个凸壳互不相交。

综上所述，定理得证。

## k 近邻

KNN 是一种分类与回归方法。三要素为：

- k 值的选择
- 距离度量
- 分类决策

### KNN 算法

KNN 没有显示的学习过程

![KNN](./机器学习方法.assets/7.png)

### KNN 模型

根据三要素（训练集、距离度量、k值、分类决策规则）确定 KNN 模型后，相当于将特征空间划分为子空间，确定子空间里的每个点所属的类

单元：对每个训练实例点，距离该点比其他点更近的所有点组成的区域；所有训练实例点的单元构成对特征空间的一个划分

距离度量：两个实例点相似程度  
- $L_p$ 距离
- p=1，曼哈顿距离 Manhattan distance
- p=2，欧氏距离 Euclidean distance
- p=inf，各个坐标最大值

![L_p距离间的关系](./机器学习方法.assets/8.png)

k 值的选择  
- k 较小：增大学习估计误差，减少学习近似误差，模型更复杂，容易过拟合
- k 较大：减少学习估计误差，增大学习近似误差，模型更简单，容易欠拟合

分类决策规则  
- 多数表决规则 majority voting rule
- 多数表决规则等价于经验风险最小化

### KNN 的实现: kd Tree

KNN 主要问题：如何对训练数据进行快速 k 近邻搜索

构造 td 树

1. 开始构造根节点，选维度数值方差最大的作为起始
2. 重复：对深度为 j 的节点，选择 $x^{(I)} I=j mod k +1$ 作为切分轴，中位数切分
3. 直到两个子区域没有实例时停止

搜索 td 树

1. 寻找当前最近点：从根节点出发
2. 回溯：从该节点出发，更新当前最近节点，检查子节点的父节点的另一子节点对应的区域是否有更近的点（画圆圈看是否和超平面有交集）
3. 回退到根节点，搜索结束，最后当前最近点为 x 的最近邻点

## 朴素贝叶斯

### 朴素贝叶斯基础

贝叶斯定理

$$
P(Y=c_i|X=x)=\frac{P(X=x|Y=c_i)\cdot P(Y=c_i)}{\sum_{i=1}^K P(X=x|Y=c_i)\cdot P(Y=c_i)}
$$

贝叶斯分类

$$
P(Y = c_i|X = x) = \frac{P(X = x|Y = c_i) \cdot P(Y = c_i)}{\sum_{i=1}^K P(X = x|Y = c_i) \cdot P(Y = c_i)}  \\
\arg \max_{c_i} P(X = x|Y = c_i) \cdot P(Y = c_i)
$$

朴素 = 假设特征之间相互独立（条件独立性假设）

朴素贝叶斯分类

$$
P(Y = c_i|X = x) = \frac{P(Y = c_i) \prod_{j=1}^n P(X^{(j)} = x^{(j)}|Y = c_i)}{\sum_{i=1}^K P(Y = c_i) \prod_{j=1}^n P(X^{(j)} = x^{(j)}|Y = c_i)}  \\
\arg \max_{c_i} P(Y = c_i) \prod_{j=1}^n P(X^{(j)} = x^{(j)}|Y = c_i)
$$

0-1损失函数最小化 -> 期望风险最小化 = 后验概率最大化

$$
L(Y, f(X)) = \begin{cases}
1, & Y \neq f(X) \\
0, & Y = f(X)
\end{cases}  \\

R(f) = E[L(Y, f(X))]  \\

f(x) = \arg \max_{c_i} P(c_i|X = x)
$$

### 极大似然估计

极大似然估计：使似然函数（联合密度函数）达到最大的参数值

似然函数

$$
L(\beta)=L(x_1,\cdots,x_N;\beta)
$$

极大似然估计

$$
\hat{\beta} = \arg \max_{\beta \in \Theta} L(x_1, \cdots, x_N; \beta)
$$

### 朴素贝叶斯算法

先验概率 + 条件概率 => 后验概率 => 分类

### 贝叶斯估计

先验概率 -> 调整因子 -> 后验概率 

先验概率的贝叶斯估计

$$
P_\lambda(Y = c_k) = \frac{\sum_{i=1}^N I(y_i = c_k) + \lambda}{N + K\lambda}
$$

条件概率的贝叶斯估计

$$
P_\lambda(X^{(j)} = a_{jl}|Y = c_k) = \frac{\sum_{i=1}^N I(x_i^{(j)} = a_{jl}, y_i = c_k) + \lambda}{\sum_{i=1}^N I(y_i = c_k) + S_j\lambda}
$$

注：$\lambda \geq 0$，$\lambda = 0$时为极大似然估计，$\lambda = 1$时为拉普拉斯平滑(Laplacian Smoothing)。

## 决策树

人类两大思维：归纳法（决策树），演绎法（第一性原理）

决策树是通过一系列if-then规则对数据进行分类的过程

- 决策树：给定特征条件下类的 $P(Y|X)$
- 条件概率分布：特征空间的一个划分 Partition
- 划分：单元 Cell 或区域 Region 互不相交

### 决策树的学习

- 本质：从训练数据集中归纳出一组分类规则，与训练数据集不相矛盾
- 假设空间：由无穷多个条件概率模型构成
- 什么是好的DT：训练中拟合较好，同时泛化性较好
- 策略：最小化损失函数
- 特征选择：递归选择最优特征
- 生成：特征空间的划分，直到所有训练子集被正确分类
- 剪枝：避免过拟合

### 信息增益: 熵(Entropy)

熵表示随机变量不确定性

$$
H(p)=-\sum_{i=1}^n p_i \log p_i
$$

随机变量取值等概率分布，熵最大

$$
0 <= H(p) <= \log n
$$

条件熵

$$
H(Y|X)=-\sum_{i=1}^n p_i H(Y|X=x_i)  \\
p_i=P(X=x_i)
$$

数据估计得到的为：经验熵，经验条件熵

信息增益：得知特征 X 而使类 Y 的信息的不确定性减少的程度

$$
g(D,A)=H(D)-H(D|A)
$$

信息增益比：解决取值数量多与少影响熵值的情况

$$
g_R(D,A) = \frac{g(D,A)}{H_A(D)}  \\
H_A(D) = -\sum_{k=1}^K \frac{|D_k|}{|D|} \log_2 \frac{|D_k|}{|D|}
H(D) = -\sum_{k=1}^K \frac{|C_k|}{|D|} \log_2 \frac{|C_k|}{|D|}
$$

### 决策树的生成

#### ID3

```pseudocode
输入: 训练数据集 D, 特征集 A, 阈值 ε
输出: 决策树 T

函数 构建决策树(D, A, ε):
    如果 D 中所有实例属于同一类:
        T = 创建叶节点(类别 = D中实例的类别)
        返回 T
    
    如果 D 中所有实例无任何特征 (A = ∅):
        T = 创建叶节点(类别 = D中实例数最多的类别)
        返回 T
    
    对于 A 中每个特征 a:
        计算信息增益 Gain(D, a)
    
    Ag = 信息增益最大的特征
    
    如果 Gain(D, Ag) < ε:
        T = 创建叶节点(类别 = D中实例数最多的类别)
        返回 T
    
    否则:
        T = 创建内部节点(特征 = Ag)
        对于 Ag 的每个可能值 ai:
            Di = D 中 Ag = ai 的子集
            Ti = 构建决策树(Di, A - {Ag}, ε)
            将 Ti 作为 T 的子树添加
        返回 T

T = 构建决策树(D, A, ε)
返回 T
```

#### C4.5

## 逻辑斯谛回归与最大熵模型

## 支持向量机

## Boosting

## EM 算法及其推广

## 隐马尔可夫模型

## 条件随机场

## 监督学习总结

# 无监督学习

# 深度学习

## 前馈神经网络

主要用于监督学习: feedforward neural network, multilayer perceptron, deep neural network (layer>2)

- 整个神经网络是对多个输入信号进行多次非线形转换产生多个输出信号的复合函数
- 学习算法：反向传播 BP
- 损失函数：分类=交叉熵，回归=平方损失，最小化等价于极大似然估计
- 正则化方法：L2, dropout, early stopping

### MLP定义

神经元的定义

$$
y = f(x_1, x_2, \cdots, x_n) = a\left(\sum_{i=1}^n w_i x_i + b\right)
$$

- x: input
- y: output
- z: intermediate output, net input
- w, b: weight, bias
- a: activation function

向量表示

$$
y=f(x)=a(\bold{w}^T x+b)
$$

MLP第一层的神经元的定义

$$
h_j^{(1)} = a\left(z_j^{(1)}\right) = a\left(\sum_{i=1}^n w_{ji}^{(1)} x_i + b_j^{(1)}\right), \quad j = 1,2,\ldots,m
$$

MLP结构

![MLP 2 layers](./机器学习方法.assets/9.png)

矩阵表示

$$
h^{(1)} = f^{(1)}(x) = a(z^{(1)}) = a\left(W^{(1)\mathrm{T}}x + b^{(1)}\right)  \\
y = f^{(2)}\left(h^{(1)}\right) = g(z^{(2)}) = g\left(W^{(2)\mathrm{T}}h^{(1)} + b^{(2)}\right)
$$

多层MLP神经元定义，第 t 层的第 j 个神经元

$$
h_j^{(t)} = a\left(z_j^{(t)}\right) = a\left(\sum_{i=1}^n w_{ji}^{(t)} h_i^{(t-1)} + b_j^{(t)}\right), \quad j = 1,2,\ldots,m
$$

多层MLP矩阵表示

$$
\begin{cases}
h^{(1)} = f^{(1)}(x) = a(z^{(1)}) = a\left(W^{(1)\mathrm{T}}x + b^{(1)}\right) \\
h^{(2)} = f^{(2)}(h^{(1)}) = a(z^{(2)}) = a\left(W^{(2)\mathrm{T}}h^{(1)} + b^{(2)}\right) \\
\vdots \\
h^{(s-1)} = f^{(s-1)}(h^{(s-2)}) = a(z^{(s-1)}) = a\left(W^{(s-1)\mathrm{T}}h^{(s-2)} + b^{(s-1)}\right) \\
y = h^{(s)} = f^{(s)}(h^{(s-1)}) = g(z^{(s)}) = g\left(W^{(s)\mathrm{T}}h^{(s-1)} + b^{(s)}\right)
\end{cases}
$$

常见激活函数

- Sigmoid: $a(z)=\frac{1}{1+e^{-z}}$ , $a'(z)=a(z)(1-a(z))$
- tanh: $a(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$ , $a'(z)=1-a(z)^2$
- ReLU: $a(z)=\max(0,z)$ , $a'(z)=\begin{cases}1 & \text{if } z > 0 \\ 0 & \text{if } z \leq 0\end{cases}$

激活函数：左饱和，右饱和，饱和

模型

- 回归: $y=f(x)$ 一维输出层，输出一个实数值
- 二分类: $p=P(y=1|x)=f(x), y\in {0,1}$
- 多分类: $p=\[P(y_k=1|x)\]=f(x), y\in {0,1}, k=1,2,\ldots,l$ 输出l个概率值组成的概率向量
- 多标签分类: $p=\[P(y_k=1|x)\]=f(x), y\in {0,1}, k=1,2,\ldots,l$ 输出l个神经元，每个神经元的输出是一个概率值

输出层神经元

- 回归: $y = g(z) = z, z = w^{(s)T}h^{(s-1)} + b^{(s)}$
- 二分类: $P(y=1|x) = g(z) = \frac{1}{1+e^{-z}}, z = w^{(s)T}h^{(s-1)} + b^{(s)}$
- 多分类: $P(y_k=1|x) = g(z_k) = \frac{e^{z_k}}{\sum_{i=1}^l e^{z_i}}, z_k = w_k^{(s)T}h^{(s-1)} + b_k^{(s)}, k=1,2,\ldots,l$
- 多标签分类: $P(y_k=1|x) = g(z_k) = \frac{1}{1+e^{-z_k}}, z_k = w_k^{(s)T}h^{(s-1)} + b_k^{(s)}, k=1,2,\ldots,l$

### MLP的表示能力

MLP与其他模型的关系

- 对多分类的一层MLP，MLP是逻辑回归模型的扩展
- 对二分类的一层MLP，MLP是感知机模型的扩展
- 对二分类的多层MLP，MLP和非线形支持向量机对应
  - SVM学习是凸优化问题，保证可以找到全局最优
  - MLP学习是非凸优化问题，不保证找到全局最优
  - MLP比SVM能学习更多的参数

MLP有强大的函数近似能力

- 通用近似定理(universal approximation theorem)：存在一个二层前馈神经网络，具有一个线性输出层和一个隐层，其中隐层含有充分数量的神经元，激活函数为挤压函数，这个网络可以以任意精度近似任意一个在紧的定义域上的连续函数
- 挤压函数: 设有实函数 $G(x): \mathcal{R} \rightarrow [0, 1]$，如果 $G(x)$ 是非减函数，且满足 $\lim_{x \rightarrow -\infty} G(x) = 0$，$\lim_{x \rightarrow +\infty} G(x) = 1$，则称函数 $G(x)$ 为挤压函数（squashing function）。S 型函数是一种挤压函数
- 后续理论研究发现，定理的条件可以放宽，当激活函数是多项式函数以外的其他函数时，或者当被近似函数是波莱尔可测函数时，定理的结论依然成立
- 波莱尔可测函数包括连续函数、分段连续函数、阶梯函数

![universal approximation theorem](./机器学习方法.assets/10.png)

MLP有大量等价函数

MLP的复杂度：宽度，深度

在同等表示能力下，深度神经网络比浅度神经网络有更少的参数，有更低的样本复杂度(sample complexity)

### MLP学习算法

#### 一般形式

有监督学习，目标是学习一个MLP模型 $f(\bold{x};\bold{\hat{\theta}})$

学习前已经确定网络的架构，包括网络的层数、每层的神经元数、神经元激活函数的类型，需要从训练数据集中学习或估计的是网络的参数值

学习问题形式化为优化问题:

$$
\hat{\theta} = \arg\min_{\theta} \left[ \sum_{i=1}^N L(f(x_i;\theta), y_i) + \lambda \cdot \Omega(f) \right]
$$

- $L(\cdot)$ 是损失函数
- $\Omega(\cdot)$ 是正则项
- $\lambda \geq 0$ 是系数

当损失函数是对数损失函数、没有正则化时，问题变成极大似然估计。这是前馈神经网络学习的一般形式

$$
\hat{\theta} = \arg\min_{\theta} \left[- \sum_{i=1}^N \log P_{\theta}(y_i|x_i)\right] \tag{23.30}
$$

- $P_\theta(y|x)$ 表示输入 x 在给定条件下输出 y 的条件概率，由参数决定
- $\theta$ 是网络的参数

#### 回归的形式

问题定义

- 输入：实数向量 $x$
- 输出：实数值 $y$
- 条件概率分布：$P_\theta(y|x)$

模型假设

- 假设条件概率分布服从高斯分布：$P_\theta(y|x) \sim N(f(x;\theta), \sigma^2)$
- $f(x;\theta)$ 是均值，$\sigma^2$ 是方差
- $y \in (-\infty, +\infty)$

学习问题（极大似然估计），优化目标：

$$
\hat{\theta} = \arg\min_{\theta} \left[\frac{1}{2\sigma^2} \sum_{i=1}^N (y_i - f(x_i;\theta))^2 + N \log \sigma + \frac{N}{2} \log 2\pi\right]
$$

等价的优化问题：

$$
\hat{\theta} = \arg\min_{\theta} \sum_{i=1}^N \frac{1}{2}(y_i - f(x_i;\theta))^2
$$

关键点

1. 回归问题使用均方损失（square loss）作为损失函数
2. 学习过程实际上是最小化均方损失
3. 这种方法等价于假设输出服从高斯分布，并进行极大似然估计
4. 当假设方差固定时，问题简化为经典的最小二乘问题

#### 二分类的形式

问题定义

- 输入：实数向量 $x$
- 输出：类别 $y \in \{0,1\}$

神经网络 $f(x;\theta)$ 表示输入给定条件下类别的条件概率分布：

$$
p = P_\theta(y = 1|x) = f(x;\theta)
$$

假设条件概率分布 $P_\theta(y = 1|x)$ 遵循伯努利分布，学习问题（极大似然估计）变为优化问题：

$$
\hat{\theta} = \arg\min_{\theta} \left\{- \sum_{i=1}^N [y_i \log f(x;\theta) + (1 - y_i) \log(1 - f(x;\theta))]\right\}
$$

损失函数

- 使用交叉熵（cross entropy）损失
- 交叉熵的一般定义：$-\sum_{k=1}^l P_k \log Q_k$
  - $Q_k$：预测分布的概率
  - $P_k$：经验分布的概率

关键点

1. 二类分类问题使用sigmoid函数作为输出层
2. 交叉熵作为损失函数，反映经验分布和预测分布的差异
3. 优化目标是最小化负对数似然，等价于最小化交叉熵

#### 多分类的形式

问题定义

- 输入：实数向量 $x$
- 输出：类别 $y_k \in \{0,1\}, k=1,2,\cdots,l$
- 约束：$\sum_{k=1}^l y_k = 1$

神经网络 $f(x;\theta)$ 表示输入给定条件下类别的条件概率分布：

$$
p = P_\theta(y_k = 1|x) = f(x;\theta)
$$

假设条件概率分布 $P_\theta(y_k = 1|x)$ 遵循类别分布（categorical distribution），学习问题变为优化问题：

$$
\hat{\theta} = \arg\min_{\theta} \left\{- \sum_{i=1}^N \left[\sum_{k=1}^l y_{ik}\log f(x;\theta)\right]\right\}
$$

- $y_{ik} \in \{0,1\}, \sum_{k=1}^l y_{ik} = 1, k=1,2,\cdots,l, i=1,2,\cdots,N$
- 前馈神经网络用于二类和多类分类时以交叉熵为损失函数，进行的是交叉熵的最小化

关键点

1. 多类分类问题中，输出是互斥的类别
2. 使用softmax函数作为输出层，保证概率和为1
3. 交叉熵作为损失函数
4. 优化目标是最小化负对数似然

### MLP学习的优化算法

目标函数一般是非凸函数，优化问题是非凸优化

$$
\hat{\theta}=\argmin_\theta L(\theta)=\argmin_\theta \frac{1}{N} \sum_{i=1}^N L(f(x_i;\theta),y_i)
$$

- 梯度下降法
- 随机梯度下降法

### 反向传播算法

### 计算图上的实现

### 算法实现技巧

### 正则化

## 卷积神经网络

## 循环神经网络

## 序列到序列模型

## 预训练语言模型

## 生成对抗网络
